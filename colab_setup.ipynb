{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHrB4niuI8h"
      },
      "source": [
        "# üè• ShifaMind - Google Colab Setup\n",
        "\n",
        "**One-click setup for running ShifaMind on Google Colab**\n",
        "\n",
        "This notebook will:\n",
        "1. Mount your Google Drive (where your data is stored)\n",
        "2. Clone the ShifaMind repository\n",
        "3. Install only the dependencies Colab doesn't have\n",
        "4. Configure paths to your Google Drive data\n",
        "5. Run the complete pipeline\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Your Google Drive should have data organized like this:\n",
        "\n",
        "```\n",
        "My Drive/\n",
        "‚îî‚îÄ‚îÄ ShifaMind/\n",
        "    ‚îî‚îÄ‚îÄ 01_Raw_Datasets/\n",
        "        ‚îî‚îÄ‚îÄ Extracted/\n",
        "            ‚îú‚îÄ‚îÄ umls-2025AA-metathesaurus-full/\n",
        "            ‚îÇ   ‚îî‚îÄ‚îÄ 2025AA/META/\n",
        "            ‚îÇ       ‚îú‚îÄ‚îÄ MRCONSO.RRF\n",
        "            ‚îÇ       ‚îú‚îÄ‚îÄ MRDEF.RRF\n",
        "            ‚îÇ       ‚îî‚îÄ‚îÄ MRSTY.RRF\n",
        "            ‚îú‚îÄ‚îÄ icd10cm-CodesDescriptions-2024/\n",
        "            ‚îÇ   ‚îî‚îÄ‚îÄ icd10cm-codes-2024.txt\n",
        "            ‚îú‚îÄ‚îÄ mimic-iv-3.1/\n",
        "            ‚îÇ   ‚îî‚îÄ‚îÄ (MIMIC-IV files)\n",
        "            ‚îî‚îÄ‚îÄ mimic-iv-note-2.2/note/\n",
        "                ‚îî‚îÄ‚îÄ discharge.csv.gz\n",
        "```\n",
        "\n",
        "**If your paths are different**, you'll set them in Step 3.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_S0hcl-uI8j"
      },
      "source": [
        "## Step 1: Mount Google Drive\n",
        "\n",
        "This connects your Google Drive to Colab so we can access your data files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X4luNWqjuI8j",
        "outputId": "ba1cc087-6dea-4bc5-fbdf-694fe7d577f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify mount\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    print(\"‚úÖ Google Drive mounted successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå Drive mount failed. Please try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpUQ65ARuI8j"
      },
      "source": [
        "## Step 2: Clone ShifaMind Repository\n",
        "\n",
        "This downloads the ShifaMind code from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-QesmT0luI8j",
        "outputId": "6546e41a-c2cb-4232-fc20-535699b6bd9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Cloning ShifaMind repository...\n",
            "Cloning into '/content/ShifaMind_Capstone'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 19 (delta 3), reused 8 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (19/19), 67.87 KiB | 13.57 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/ShifaMind_Capstone\n",
            "\n",
            "‚úÖ Repository cloned successfully!\n",
            "üìÇ Current directory: /content/ShifaMind_Capstone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Remove existing clone if present\n",
        "if os.path.exists('/content/ShifaMind_Capstone'):\n",
        "    print(\"üóëÔ∏è  Removing existing ShifaMind directory...\")\n",
        "    !rm -rf /content/ShifaMind_Capstone\n",
        "\n",
        "# Clone repository\n",
        "print(\"üì• Cloning ShifaMind repository...\")\n",
        "!git clone https://github.com/SyedMohammedSameer/ShifaMind_Capstone.git /content/ShifaMind_Capstone\n",
        "\n",
        "# Change to repo directory\n",
        "%cd /content/ShifaMind_Capstone\n",
        "\n",
        "print(\"\\n‚úÖ Repository cloned successfully!\")\n",
        "print(\"üìÇ Current directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05nDhlaMuI8k"
      },
      "source": [
        "## Step 3: Configure Data Paths\n",
        "\n",
        "**DEFAULT PATHS (Most users can skip this)**\n",
        "\n",
        "If your data is at `/content/drive/MyDrive/ShifaMind/01_Raw_Datasets/`, just run this cell as-is.\n",
        "\n",
        "**CUSTOM PATHS**\n",
        "\n",
        "If your data is elsewhere, modify the `BASE_PATH` variable below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W_2a82e6uI8k",
        "outputId": "a718e99f-ce12-413a-d2ed-114d9f50458a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Validating data paths...\n",
            "\n",
            "Base Path: /content/drive/MyDrive/ShifaMind\n",
            "======================================================================\n",
            "‚úÖ Base Directory\n",
            "‚úÖ Raw Datasets\n",
            "‚úÖ UMLS MRCONSO\n",
            "‚úÖ ICD-10 Codes\n",
            "‚úÖ MIMIC Notes\n",
            "======================================================================\n",
            "\n",
            "üéâ All paths validated! Ready to proceed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURE YOUR DATA PATH HERE\n",
        "# ============================================================================\n",
        "\n",
        "# Option 1: Use default path (recommended)\n",
        "BASE_PATH = \"/content/drive/MyDrive/ShifaMind\"\n",
        "\n",
        "# Option 2: Use custom path (uncomment and modify if needed)\n",
        "# BASE_PATH = \"/content/drive/MyDrive/YourCustomFolder/ShifaMind\"\n",
        "\n",
        "# ============================================================================\n",
        "# SET ENVIRONMENT VARIABLE\n",
        "# ============================================================================\n",
        "\n",
        "os.environ['SHIFAMIND_BASE_PATH'] = BASE_PATH\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATE PATHS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"üîç Validating data paths...\\n\")\n",
        "print(f\"Base Path: {BASE_PATH}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check critical paths\n",
        "paths_to_check = {\n",
        "    \"Base Directory\": BASE_PATH,\n",
        "    \"Raw Datasets\": f\"{BASE_PATH}/01_Raw_Datasets\",\n",
        "    \"UMLS MRCONSO\": f\"{BASE_PATH}/01_Raw_Datasets/Extracted/umls-2025AA-metathesaurus-full/2025AA/META/MRCONSO.RRF\",\n",
        "    \"ICD-10 Codes\": f\"{BASE_PATH}/01_Raw_Datasets/Extracted/icd10cm-CodesDescriptions-2024/icd10cm-codes-2024.txt\",\n",
        "    \"MIMIC Notes\": f\"{BASE_PATH}/01_Raw_Datasets/Extracted/mimic-iv-note-2.2/note/discharge.csv.gz\",\n",
        "}\n",
        "\n",
        "all_exist = True\n",
        "for name, path in paths_to_check.items():\n",
        "    exists = Path(path).exists()\n",
        "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "    print(f\"{status} {name}\")\n",
        "    if not exists:\n",
        "        all_exist = False\n",
        "        print(f\"   Missing: {path}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "if all_exist:\n",
        "    print(\"\\nüéâ All paths validated! Ready to proceed.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Some paths are missing. Please:\")\n",
        "    print(\"   1. Verify your BASE_PATH is correct\")\n",
        "    print(\"   2. Ensure data files are uploaded to Google Drive\")\n",
        "    print(\"   3. Check folder and file names match exactly\")\n",
        "    print(\"\\n   Then re-run this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gnxHnPLuI8k"
      },
      "source": [
        "## Step 4: Install Dependencies\n",
        "\n",
        "Colab already has most packages (PyTorch, NumPy, pandas, etc.). We only install what's missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VJLhbogVuI8k",
        "outputId": "e4fbfa09-8076-41b8-b964-18417fc56be1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing missing dependencies...\n",
            "\n",
            "Note: This may take 2-3 minutes.\n",
            "\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "üì• Downloading medical NLP model...\n",
            "\n",
            "\u001b[38;5;1m‚úò No compatible package found for 'en_core_sci_sm' (spaCy v3.8.8)\u001b[0m\n",
            "\n",
            "\n",
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "print(\"üì¶ Installing missing dependencies...\\n\")\n",
        "print(\"Note: This may take 2-3 minutes.\\n\")\n",
        "\n",
        "# Install only packages not in Colab by default\n",
        "!pip install -q transformers>=4.35.0\n",
        "!pip install -q gradio>=4.0.0\n",
        "!pip install -q scispacy>=0.5.3\n",
        "!pip install -q jsonlines>=3.1.0\n",
        "!pip install -q plotly>=5.14.0\n",
        "\n",
        "# Download spacy medical model\n",
        "print(\"\\nüì• Downloading medical NLP model...\")\n",
        "!python -m spacy download en_core_sci_sm\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2ipYhHsuI8k"
      },
      "source": [
        "## Step 5: Verify GPU Access\n",
        "\n",
        "ShifaMind runs much faster on GPU. Let's check if GPU is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DHcSsiR2uI8k",
        "outputId": "3fa7ac1d-64bb-42b9-f495-441801f6c5f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU Available: NVIDIA A100-SXM4-40GB\n",
            "   Memory: 42.5 GB\n",
            "\n",
            "üöÄ Training will use GPU acceleration!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
        "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
        "    print(f\"\\nüöÄ Training will use GPU acceleration!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Training will use CPU (much slower).\")\n",
        "    print(\"\\nüí° To enable GPU in Colab:\")\n",
        "    print(\"   1. Go to Runtime > Change runtime type\")\n",
        "    print(\"   2. Select 'T4 GPU' or 'A100 GPU'\")\n",
        "    print(\"   3. Click Save\")\n",
        "    print(\"   4. Restart from Step 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sEul_nBuI8k"
      },
      "source": [
        "---\n",
        "\n",
        "# üöÄ Pipeline Execution\n",
        "\n",
        "Now that setup is complete, run the ShifaMind pipeline in order.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usHhWTxduI8k"
      },
      "source": [
        "## Pipeline Step 1: Generate Knowledge Base\n",
        "\n",
        "**Time**: ~5-10 minutes\n",
        "\n",
        "This parses UMLS and ICD-10 to create a structured medical knowledge base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "3tZQia9zuI8k",
        "outputId": "f079e970-5cf1-4949-cb38-2308eacc9f2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ShifaMind_Capstone\n",
            "üèóÔ∏è  Generating Clinical Knowledge Base...\n",
            "\n",
            "================================================================================\n",
            "SHIFAMIND: CLINICAL KNOWLEDGE BASE GENERATOR\n",
            "================================================================================\n",
            "2025-11-21 00:08:09,153 - INFO - UMLS Path: /content/drive/MyDrive/ShifaMind/01_Raw_Datasets/Extracted/umls-2025AA-metathesaurus-full/2025AA/META\n",
            "2025-11-21 00:08:09,153 - INFO - ICD-10 Path: /content/drive/MyDrive/ShifaMind/01_Raw_Datasets/Extracted/icd10cm-CodesDescriptions-2024\n",
            "2025-11-21 00:08:09,153 - INFO - Output: /content/drive/MyDrive/ShifaMind/03_Models/clinical_knowledge_base.json\n",
            "2025-11-21 00:08:09,154 - INFO - ================================================================================\n",
            "2025-11-21 00:08:09,154 - INFO - STARTING FILTERED KNOWLEDGE BASE GENERATION\n",
            "2025-11-21 00:08:09,154 - INFO - ================================================================================\n",
            "2025-11-21 00:08:09,154 - INFO - \n",
            "üîç Validating file paths...\n",
            "2025-11-21 00:08:09,157 - INFO -   ‚úÖ MRCONSO: 2128.5 MB\n",
            "2025-11-21 00:08:09,158 - INFO -   ‚úÖ ICD-10: 6.1 MB\n",
            "2025-11-21 00:08:09,158 - INFO - ======================================================================\n",
            "2025-11-21 00:08:09,158 - INFO - PARSING ICD-10 CODES\n",
            "2025-11-21 00:08:09,158 - INFO - ======================================================================\n",
            "2025-11-21 00:08:09,158 - INFO - File: /content/drive/MyDrive/ShifaMind/01_Raw_Datasets/Extracted/icd10cm-CodesDescriptions-2024/icd10cm-codes-2024.txt\n",
            "2025-11-21 00:08:10,432 - INFO -   ‚úÖ Loaded 74044 ICD-10 codes\n",
            "2025-11-21 00:08:10,432 - INFO - ======================================================================\n",
            "2025-11-21 00:08:10,432 - INFO - PARSING MRCONSO.RRF - Concept Names (WITH FILTERING)\n",
            "2025-11-21 00:08:10,432 - INFO - ======================================================================\n",
            "2025-11-21 00:08:10,432 - INFO - File: /content/drive/MyDrive/ShifaMind/01_Raw_Datasets/Extracted/umls-2025AA-metathesaurus-full/2025AA/META/MRCONSO.RRF\n",
            "2025-11-21 00:08:10,432 - INFO - Size: 2.08 GB\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ShifaMind_Capstone/final_knowledge_base_generator.py\", line 557, in <module>\n",
            "    main(output_path=args.output)\n",
            "  File \"/content/ShifaMind_Capstone/final_knowledge_base_generator.py\", line 485, in main\n",
            "    concepts = load_concept_names(MRCONSO_PATH, DIAGNOSIS_KEYWORDS)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ShifaMind_Capstone/final_knowledge_base_generator.py\", line 105, in load_concept_names\n",
            "    for category_keywords in dx_keywords.values():\n",
            "                             ^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'list' object has no attribute 'values'\n",
            "\n",
            "‚úÖ Knowledge base generated!\n",
            "üìÑ Output: 03_Models/clinical_knowledge_base.json\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ShifaMind_Capstone\n",
        "\n",
        "print(\"üèóÔ∏è  Generating Clinical Knowledge Base...\\n\")\n",
        "!python final_knowledge_base_generator.py\n",
        "\n",
        "print(\"\\n‚úÖ Knowledge base generated!\")\n",
        "print(\"üìÑ Output: 03_Models/clinical_knowledge_base.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luh-GwAiuI8l"
      },
      "source": [
        "## Pipeline Step 2: Train Model\n",
        "\n",
        "**Time**: ~6 hours on GPU (T4), ~1 hour on A100\n",
        "\n",
        "This trains ShifaMind through 3 stages:\n",
        "- Stage 1: Diagnosis head (3 epochs)\n",
        "- Stage 2: Concept head (2 epochs)\n",
        "- Stage 3: Joint fine-tuning (3 epochs)\n",
        "\n",
        "**‚ö†Ô∏è Important**: This is a long-running process. Make sure:\n",
        "1. You have GPU enabled\n",
        "2. Your Colab session won't timeout (keep browser tab active or use Colab Pro)\n",
        "3. You have enough Google Drive space for model checkpoints (~2GB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "rvZtOkzIuI8l",
        "outputId": "5c145646-86cc-40ae-9e1f-786cd7f6c436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ShifaMind_Capstone\n",
            "üéì Training ShifaMind Model...\n",
            "\n",
            "This will take several hours. Progress will be shown below.\n",
            "\n",
            "======================================================================\n",
            "2025-11-21 00:08:49,151 - INFO - üñ•Ô∏è  Device: cuda\n",
            "2025-11-21 00:08:49,727 - INFO - ================================================================================\n",
            "2025-11-21 00:08:49,727 - INFO - SHIFAMIND: MODEL TRAINING PIPELINE\n",
            "2025-11-21 00:08:49,727 - INFO - ================================================================================\n",
            "2025-11-21 00:08:49,727 - INFO - Output Directory: /content/drive/MyDrive/ShifaMind/04_Results/experiments/training_run\n",
            "2025-11-21 00:08:49,727 - INFO - Checkpoint Directory: /content/drive/MyDrive/ShifaMind/03_Models/checkpoints\n",
            "2025-11-21 00:08:49,727 - INFO - ======================================================================\n",
            "2025-11-21 00:08:49,727 - INFO - DATA VALIDATION\n",
            "2025-11-21 00:08:49,727 - INFO - ======================================================================\n",
            "2025-11-21 00:08:49,728 - INFO -    ‚úÖ MIMIC Notes: 1086.4 MB\n",
            "2025-11-21 00:08:49,729 - INFO -    ‚úÖ UMLS MRCONSO: 2128.5 MB\n",
            "2025-11-21 00:08:49,730 - INFO -    ‚úÖ UMLS MRSTY: 205.2 MB\n",
            "2025-11-21 00:08:51,219 - INFO -    ‚úÖ MIMIC Diagnoses: 32.0 MB\n",
            "2025-11-21 00:08:51,219 - INFO -    ‚úÖ Output Directory: exists\n",
            "2025-11-21 00:08:51,220 - INFO -    ‚úÖ Checkpoint Directory: exists\n",
            "2025-11-21 00:08:51,220 - INFO - ‚úÖ All data validation checks passed\n",
            "2025-11-21 00:08:51,220 - INFO - ======================================================================\n",
            "2025-11-21 00:08:51,220 - INFO - LOADING TARGETED CONCEPTS FROM UMLS\n",
            "2025-11-21 00:08:51,220 - INFO - ======================================================================\n",
            "2025-11-21 00:08:51,220 - INFO - ======================================================================\n",
            "2025-11-21 00:08:51,220 - INFO - TARGETED UMLS CONCEPT LOADING\n",
            "2025-11-21 00:08:51,220 - INFO - ======================================================================\n",
            "2025-11-21 00:08:51,220 - INFO - üéØ Searching UMLS for 71 specific medical terms:\n",
            "2025-11-21 00:08:51,220 - INFO -    J189: 20 terms\n",
            "2025-11-21 00:08:51,220 - INFO -    I5023: 20 terms\n",
            "2025-11-21 00:08:51,220 - INFO -    A419: 21 terms\n",
            "2025-11-21 00:08:51,220 - INFO -    K8000: 17 terms\n",
            "2025-11-21 00:08:51,220 - INFO - üìñ Scanning MRCONSO (17M+ entries)...\n",
            "2025-11-21 00:08:51,220 - INFO -    This will take ~30-60 seconds...\n",
            "  Searching: 17144356it [00:58, 294734.44it/s]\n",
            "2025-11-21 00:09:49,391 - INFO -   ‚úÖ Found 9970 unique concepts\n",
            "2025-11-21 00:09:49,391 - INFO -   üìä Coverage per diagnosis:\n",
            "2025-11-21 00:09:49,392 - INFO -     J189: 3190 concepts (20 terms searched)\n",
            "2025-11-21 00:09:49,392 - INFO -     I5023: 3845 concepts (20 terms searched)\n",
            "2025-11-21 00:09:49,392 - INFO -     A419: 3035 concepts (21 terms searched)\n",
            "2025-11-21 00:09:49,393 - INFO -     K8000: 1879 concepts (17 terms searched)\n",
            "2025-11-21 00:09:49,393 - INFO - üìã Loading semantic types...\n",
            "2025-11-21 00:09:54,461 - INFO -   ‚úÖ Added semantic types for 9970 concepts\n",
            "2025-11-21 00:09:54,461 - INFO - üìñ Loading definitions...\n",
            "2025-11-21 00:09:59,059 - INFO -   ‚úÖ Added 4140 definitions\n",
            "2025-11-21 00:09:59,060 - INFO - üîç Filtering to top-15 concepts per diagnosis...\n",
            "2025-11-21 00:09:59,065 - INFO -   J189: 15 concepts (was: 3190)\n",
            "2025-11-21 00:09:59,065 - INFO -   I5023: 15 concepts (was: 3845)\n",
            "2025-11-21 00:09:59,066 - INFO -   A419: 15 concepts (was: 3035)\n",
            "2025-11-21 00:09:59,066 - INFO -   K8000: 15 concepts (was: 1879)\n",
            "2025-11-21 00:09:59,067 - INFO -   ‚úÖ Filtered from 9970 to 60 concepts\n",
            "2025-11-21 00:09:59,067 - INFO -   ‚úÖ Expected labels per sample: ~15-30\n",
            "2025-11-21 00:09:59,068 - INFO - ‚úÖ TARGETED LOADING COMPLETE:\n",
            "2025-11-21 00:09:59,068 - INFO -    Total concepts loaded: 60\n",
            "2025-11-21 00:09:59,068 - INFO -    ICD10 mappings: 28\n",
            "2025-11-21 00:09:59,068 - INFO - ======================================================================\n",
            "2025-11-21 00:09:59,068 - INFO - LOADING MIMIC-IV DATA\n",
            "2025-11-21 00:09:59,068 - INFO - ======================================================================\n",
            "2025-11-21 00:10:56,044 - INFO - ‚úÖ Loaded MIMIC-IV data:\n",
            "2025-11-21 00:10:56,044 - INFO -    Diagnoses: 6364488\n",
            "2025-11-21 00:10:56,044 - INFO -    Notes: 331793\n",
            "2025-11-21 00:10:56,044 - INFO - üîß Preparing dataset...\n",
            "2025-11-21 00:11:02,148 - INFO -   ‚úÖ Dataset: 8604 samples\n",
            "2025-11-21 00:11:02,236 - INFO - üìä Split:\n",
            "2025-11-21 00:11:02,237 - INFO -   Train: 6022\n",
            "2025-11-21 00:11:02,237 - INFO -   Val: 1291\n",
            "2025-11-21 00:11:02,237 - INFO -   Test: 1291\n",
            "2025-11-21 00:11:02,237 - INFO - Initializing Bio_ClinicalBERT...\n",
            "config.json: 100% 385/385 [00:00<00:00, 3.75MB/s]\n",
            "vocab.txt: 213kB [00:00, 57.0MB/s]\n",
            "2025-11-21 00:11:05.963033: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-21 00:11:05.984196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763683866.008148    5318 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763683866.014732    5318 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763683866.031392    5318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763683866.031419    5318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763683866.031422    5318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763683866.031425    5318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-21 00:11:06.035965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "pytorch_model.bin: 100% 436M/436M [00:02<00:00, 208MB/s]\n",
            "2025-11-21 00:11:16,513 - INFO - üî¨ Building concept store from 60 targeted concepts...\n",
            "2025-11-21 00:11:16,513 - INFO -   ‚úÖ Stored 60 concepts\n",
            "2025-11-21 00:11:16,513 - INFO - üîó Building diagnosis-concept mappings...\n",
            "2025-11-21 00:11:16,514 - INFO -   J189: 18 relevant concepts\n",
            "2025-11-21 00:11:16,514 - INFO -   I5023: 16 relevant concepts\n",
            "2025-11-21 00:11:16,514 - INFO -   A419: 29 relevant concepts\n",
            "2025-11-21 00:11:16,514 - INFO -   K8000: 17 relevant concepts\n",
            "2025-11-21 00:11:16,514 - INFO - üß¨ Creating concept embeddings...\n",
            "  Encoding: 100% 2/2 [00:00<00:00,  4.61it/s]\n",
            "2025-11-21 00:11:16,950 - INFO -   ‚úÖ Created embeddings: torch.Size([60, 768])\n",
            "2025-11-21 00:11:16,950 - INFO - ‚úÖ Concept store complete\n",
            "2025-11-21 00:11:16,951 - INFO - ======================================================================\n",
            "2025-11-21 00:11:16,951 - INFO - MODEL ARCHITECTURE\n",
            "2025-11-21 00:11:16,951 - INFO - ======================================================================\n",
            "2025-11-21 00:11:16,999 - INFO -   Model parameters: 114,281,404\n",
            "2025-11-21 00:11:16,999 - INFO - ‚úÖ Model architecture defined and initialized\n",
            "2025-11-21 00:11:16,999 - INFO - ======================================================================\n",
            "2025-11-21 00:11:16,999 - INFO - WHITELIST LABELING FROM TARGETED CONCEPTS\n",
            "2025-11-21 00:11:16,999 - INFO - ======================================================================\n",
            "2025-11-21 00:11:16,999 - INFO - üìä Building whitelist from search results...\n",
            "2025-11-21 00:11:16,999 - INFO -   J189: 17 concepts\n",
            "2025-11-21 00:11:16,999 - INFO -   I5023: 16 concepts\n",
            "2025-11-21 00:11:16,999 - INFO -   A419: 18 concepts\n",
            "2025-11-21 00:11:16,999 - INFO -   K8000: 19 concepts\n",
            "2025-11-21 00:11:17,000 - INFO -   ‚úÖ Total whitelist concepts: 70\n",
            "2025-11-21 00:11:17,000 - INFO - ‚úÖ Whitelist ready: 60 unique concepts\n",
            "2025-11-21 00:11:17,000 - INFO - ======================================================================\n",
            "2025-11-21 00:11:17,000 - INFO - GENERATING CONCEPT LABELS\n",
            "2025-11-21 00:11:17,000 - INFO - ======================================================================\n",
            "2025-11-21 00:11:17,000 - INFO - üè∑Ô∏è  Generating labels for 6022 samples...\n",
            "  Labeling: 100% 6022/6022 [00:00<00:00, 110164.60it/s]\n",
            "2025-11-21 00:11:17,085 - INFO -   ‚úÖ Avg labels per sample: 19.3\n",
            "2025-11-21 00:11:17,085 - WARNING -   ‚ö†Ô∏è  Labels outside expected range (5-15)\n",
            "2025-11-21 00:11:17,085 - INFO - üè∑Ô∏è  Generating labels for 1291 samples...\n",
            "  Labeling: 100% 1291/1291 [00:00<00:00, 120837.44it/s]\n",
            "2025-11-21 00:11:17,106 - INFO -   ‚úÖ Avg labels per sample: 19.4\n",
            "2025-11-21 00:11:17,106 - WARNING -   ‚ö†Ô∏è  Labels outside expected range (5-15)\n",
            "2025-11-21 00:11:17,106 - INFO - üè∑Ô∏è  Generating labels for 1291 samples...\n",
            "  Labeling: 100% 1291/1291 [00:00<00:00, 116111.21it/s]\n",
            "2025-11-21 00:11:17,128 - INFO -   ‚úÖ Avg labels per sample: 19.2\n",
            "2025-11-21 00:11:17,128 - WARNING -   ‚ö†Ô∏è  Labels outside expected range (5-15)\n",
            "2025-11-21 00:11:17,128 - INFO - ‚úÖ All concept labels generated\n",
            "2025-11-21 00:11:17,128 - INFO - ======================================================================\n",
            "2025-11-21 00:11:17,129 - INFO - STAGE 1: DIAGNOSIS HEAD TRAINING\n",
            "2025-11-21 00:11:17,129 - INFO - ======================================================================\n",
            "model.safetensors:   0% 0.00/436M [00:00<?, ?B/s]2025-11-21 00:11:17,583 - INFO - Preparing data loaders...\n",
            "2025-11-21 00:11:17,584 - INFO - Starting Stage 1 training...\n",
            "2025-11-21 00:11:17,585 - INFO - Epoch 1/3\n",
            "\n",
            "Training:   0% 0/753 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0% 1/753 [00:00<07:45,  1.61it/s]\u001b[A\n",
            "model.safetensors:  39% 169M/436M [00:01<00:01, 173MB/s]     \n",
            "model.safetensors: 100% 436M/436M [00:01<00:00, 297MB/s]\n",
            "\n",
            "Training:   1% 4/753 [00:01<03:33,  3.50it/s]\u001b[A\n",
            "Training:   1% 5/753 [00:01<03:17,  3.80it/s]\u001b[A\n",
            "Training:   1% 6/753 [00:01<03:08,  3.96it/s]\u001b[A\n",
            "Training:   1% 7/753 [00:01<02:59,  4.16it/s]\u001b[A\n",
            "Training:   1% 8/753 [00:02<02:58,  4.17it/s]\u001b[A\n",
            "Training:   1% 9/753 [00:02<02:53,  4.28it/s]\u001b[A\n",
            "Training:   1% 10/753 [00:02<02:44,  4.52it/s]\u001b[A\n",
            "Training:   1% 11/753 [00:02<02:46,  4.45it/s]\u001b[A\n",
            "Training:   2% 12/753 [00:03<02:44,  4.50it/s]\u001b[A\n",
            "Training:   2% 13/753 [00:03<02:45,  4.46it/s]\u001b[A\n",
            "Training:   2% 14/753 [00:03<02:42,  4.55it/s]\u001b[A\n",
            "Training:   2% 15/753 [00:03<02:40,  4.60it/s]\u001b[A\n",
            "Training:   2% 16/753 [00:03<02:38,  4.64it/s]\u001b[A\n",
            "Training:   2% 17/753 [00:04<02:40,  4.58it/s]\u001b[A\n",
            "Training:   2% 18/753 [00:04<02:43,  4.50it/s]\u001b[A\n",
            "Training:   3% 19/753 [00:04<02:40,  4.56it/s]\u001b[A\n",
            "Training:   3% 20/753 [00:04<02:38,  4.62it/s]\u001b[A\n",
            "Training:   3% 21/753 [00:05<02:37,  4.66it/s]\u001b[A\n",
            "Training:   3% 22/753 [00:05<02:35,  4.71it/s]\u001b[A\n",
            "Training:   3% 23/753 [00:05<02:40,  4.54it/s]\u001b[A\n",
            "Training:   3% 24/753 [00:05<02:37,  4.62it/s]\u001b[A\n",
            "Training:   3% 25/753 [00:05<02:35,  4.67it/s]\u001b[A\n",
            "Training:   3% 26/753 [00:06<02:34,  4.71it/s]\u001b[A\n",
            "Training:   4% 27/753 [00:06<02:29,  4.86it/s]\u001b[A\n",
            "Training:   4% 28/753 [00:06<02:32,  4.76it/s]\u001b[A\n",
            "Training:   4% 29/753 [00:06<02:34,  4.70it/s]\u001b[A\n",
            "Training:   4% 30/753 [00:06<02:37,  4.58it/s]\u001b[A\n",
            "Training:   4% 31/753 [00:07<02:38,  4.55it/s]\u001b[A\n",
            "Training:   4% 32/753 [00:07<02:36,  4.60it/s]\u001b[A\n",
            "Training:   4% 33/753 [00:07<02:33,  4.70it/s]\u001b[A\n",
            "Training:   5% 34/753 [00:07<02:34,  4.66it/s]\u001b[A\n",
            "Training:   5% 35/753 [00:08<02:32,  4.72it/s]\u001b[A\n",
            "Training:   5% 36/753 [00:08<02:30,  4.77it/s]\u001b[A\n",
            "Training:   5% 37/753 [00:08<02:28,  4.81it/s]\u001b[A\n",
            "Training:   5% 38/753 [00:08<02:29,  4.79it/s]\u001b[A\n",
            "Training:   5% 39/753 [00:08<02:32,  4.67it/s]\u001b[A\n",
            "Training:   5% 40/753 [00:09<02:33,  4.66it/s]\u001b[A\n",
            "Training:   5% 41/753 [00:09<02:31,  4.71it/s]\u001b[A\n",
            "Training:   6% 42/753 [00:09<02:26,  4.84it/s]\u001b[A\n",
            "Training:   6% 43/753 [00:09<02:27,  4.82it/s]\u001b[A\n",
            "Training:   6% 44/753 [00:09<02:31,  4.69it/s]\u001b[A\n",
            "Training:   6% 45/753 [00:10<02:29,  4.72it/s]\u001b[A\n",
            "Training:   6% 46/753 [00:10<02:32,  4.63it/s]\u001b[A\n",
            "Training:   6% 47/753 [00:10<02:32,  4.64it/s]\u001b[A\n",
            "Training:   6% 48/753 [00:10<02:30,  4.70it/s]\u001b[A\n",
            "Training:   7% 49/753 [00:11<02:32,  4.63it/s]\u001b[A\n",
            "Training:   7% 50/753 [00:11<02:32,  4.61it/s]\u001b[A\n",
            "Training:   7% 51/753 [00:11<02:30,  4.66it/s]\u001b[A\n",
            "Training:   7% 52/753 [00:11<02:32,  4.59it/s]\u001b[A\n",
            "Training:   7% 53/753 [00:11<02:31,  4.61it/s]\u001b[A\n",
            "Training:   7% 54/753 [00:12<02:31,  4.61it/s]\u001b[A\n",
            "Training:   7% 55/753 [00:12<02:29,  4.65it/s]\u001b[A\n",
            "Training:   7% 56/753 [00:12<02:27,  4.72it/s]\u001b[A\n",
            "Training:   8% 57/753 [00:12<02:25,  4.79it/s]\u001b[A\n",
            "Training:   8% 58/753 [00:12<02:26,  4.76it/s]\u001b[A\n",
            "Training:   8% 59/753 [00:13<02:22,  4.88it/s]\u001b[A\n",
            "Training:   8% 60/753 [00:13<02:28,  4.68it/s]\u001b[A\n",
            "Training:   8% 61/753 [00:13<02:26,  4.71it/s]\u001b[A\n",
            "Training:   8% 62/753 [00:13<02:23,  4.81it/s]\u001b[A\n",
            "Training:   8% 63/753 [00:13<02:25,  4.75it/s]\u001b[A\n",
            "Training:   8% 64/753 [00:14<02:25,  4.74it/s]\u001b[A\n",
            "Training:   9% 65/753 [00:14<02:25,  4.72it/s]\u001b[A\n",
            "Training:   9% 66/753 [00:14<02:29,  4.59it/s]\u001b[A\n",
            "Training:   9% 67/753 [00:14<02:29,  4.57it/s]\u001b[A\n",
            "Training:   9% 68/753 [00:15<02:29,  4.58it/s]\u001b[A\n",
            "Training:   9% 69/753 [00:15<02:26,  4.68it/s]\u001b[A\n",
            "Training:   9% 70/753 [00:15<02:26,  4.66it/s]\u001b[A\n",
            "Training:   9% 71/753 [00:15<02:26,  4.67it/s]\u001b[A\n",
            "Training:  10% 72/753 [00:15<02:25,  4.69it/s]\u001b[A\n",
            "Training:  10% 73/753 [00:16<02:26,  4.65it/s]\u001b[A\n",
            "Training:  10% 74/753 [00:16<02:31,  4.49it/s]\u001b[A\n",
            "Training:  10% 75/753 [00:16<02:35,  4.37it/s]\u001b[A\n",
            "Training:  10% 76/753 [00:16<02:32,  4.43it/s]\u001b[A\n",
            "Training:  10% 77/753 [00:17<02:29,  4.52it/s]\u001b[A\n",
            "Training:  10% 78/753 [00:17<02:24,  4.67it/s]\u001b[A\n",
            "Training:  10% 79/753 [00:17<02:25,  4.63it/s]\u001b[A\n",
            "Training:  11% 80/753 [00:17<02:22,  4.71it/s]\u001b[A\n",
            "Training:  11% 81/753 [00:17<02:21,  4.74it/s]\u001b[A\n",
            "Training:  11% 82/753 [00:18<02:22,  4.72it/s]\u001b[A\n",
            "Training:  11% 83/753 [00:18<02:22,  4.71it/s]\u001b[A\n",
            "Training:  11% 84/753 [00:18<02:24,  4.64it/s]\u001b[A\n",
            "Training:  11% 85/753 [00:18<02:22,  4.69it/s]\u001b[A\n",
            "Training:  11% 86/753 [00:18<02:21,  4.70it/s]\u001b[A\n",
            "Training:  12% 87/753 [00:19<02:21,  4.70it/s]\u001b[A\n",
            "Training:  12% 88/753 [00:19<02:23,  4.62it/s]\u001b[A\n",
            "Training:  12% 89/753 [00:19<02:21,  4.68it/s]\u001b[A\n",
            "Training:  12% 90/753 [00:19<02:23,  4.61it/s]\u001b[A\n",
            "Training:  12% 91/753 [00:20<02:27,  4.50it/s]\u001b[A\n",
            "Training:  12% 92/753 [00:20<02:24,  4.57it/s]\u001b[A\n",
            "Training:  12% 93/753 [00:20<02:24,  4.58it/s]\u001b[A\n",
            "Training:  12% 94/753 [00:20<02:23,  4.58it/s]\u001b[A\n",
            "Training:  13% 95/753 [00:20<02:20,  4.68it/s]\u001b[A\n",
            "Training:  13% 96/753 [00:21<02:24,  4.55it/s]\u001b[A\n",
            "Training:  13% 97/753 [00:21<02:22,  4.60it/s]\u001b[A\n",
            "Training:  13% 98/753 [00:21<02:20,  4.67it/s]\u001b[A\n",
            "Training:  13% 99/753 [00:21<02:18,  4.73it/s]\u001b[A\n",
            "Training:  13% 100/753 [00:21<02:14,  4.86it/s]\u001b[A\n",
            "Training:  13% 101/753 [00:22<02:16,  4.79it/s]\u001b[A\n",
            "Training:  14% 102/753 [00:22<02:15,  4.81it/s]\u001b[A\n",
            "Training:  14% 103/753 [00:22<02:19,  4.66it/s]\u001b[A\n",
            "Training:  14% 104/753 [00:22<02:15,  4.77it/s]\u001b[A\n",
            "Training:  14% 105/753 [00:23<02:23,  4.51it/s]\u001b[A\n",
            "Training:  14% 106/753 [00:23<02:26,  4.43it/s]\u001b[A\n",
            "Training:  14% 107/753 [00:23<02:24,  4.47it/s]\u001b[A\n",
            "Training:  14% 108/753 [00:23<02:19,  4.63it/s]\u001b[A\n",
            "Training:  14% 109/753 [00:23<02:18,  4.63it/s]\u001b[A\n",
            "Training:  15% 110/753 [00:24<02:18,  4.65it/s]\u001b[A\n",
            "Training:  15% 111/753 [00:24<02:14,  4.76it/s]\u001b[A\n",
            "Training:  15% 112/753 [00:24<02:15,  4.72it/s]\u001b[A\n",
            "Training:  15% 113/753 [00:24<02:16,  4.69it/s]\u001b[A\n",
            "Training:  15% 114/753 [00:24<02:15,  4.72it/s]\u001b[A\n",
            "Training:  15% 115/753 [00:25<02:12,  4.81it/s]\u001b[A\n",
            "Training:  15% 116/753 [00:25<02:12,  4.80it/s]\u001b[A\n",
            "Training:  16% 117/753 [00:25<02:11,  4.82it/s]\u001b[A\n",
            "Training:  16% 118/753 [00:25<02:16,  4.65it/s]\u001b[A\n",
            "Training:  16% 119/753 [00:26<02:14,  4.71it/s]\u001b[A\n",
            "Training:  16% 120/753 [00:26<02:13,  4.75it/s]\u001b[A\n",
            "Training:  16% 121/753 [00:26<02:13,  4.73it/s]\u001b[A\n",
            "Training:  16% 122/753 [00:26<02:12,  4.76it/s]\u001b[A\n",
            "Training:  16% 123/753 [00:26<02:14,  4.68it/s]\u001b[A\n",
            "Training:  16% 124/753 [00:27<02:13,  4.70it/s]\u001b[A\n",
            "Training:  17% 125/753 [00:27<02:19,  4.49it/s]\u001b[A\n",
            "Training:  17% 126/753 [00:27<02:16,  4.58it/s]\u001b[A\n",
            "Training:  17% 127/753 [00:27<02:14,  4.67it/s]\u001b[A\n",
            "Training:  17% 128/753 [00:27<02:17,  4.54it/s]\u001b[A\n",
            "Training:  17% 129/753 [00:28<02:15,  4.62it/s]\u001b[A\n",
            "Training:  17% 130/753 [00:28<02:10,  4.76it/s]\u001b[A\n",
            "Training:  17% 131/753 [00:28<02:12,  4.70it/s]\u001b[A\n",
            "Training:  18% 132/753 [00:28<02:11,  4.71it/s]\u001b[A\n",
            "Training:  18% 133/753 [00:29<02:15,  4.58it/s]\u001b[A\n",
            "Training:  18% 134/753 [00:29<02:17,  4.50it/s]\u001b[A\n",
            "Training:  18% 135/753 [00:29<02:13,  4.62it/s]\u001b[A\n",
            "Training:  18% 136/753 [00:29<02:08,  4.80it/s]\u001b[A\n",
            "Training:  18% 137/753 [00:29<02:08,  4.80it/s]\u001b[A\n",
            "Training:  18% 138/753 [00:30<02:07,  4.83it/s]\u001b[A\n",
            "Training:  18% 139/753 [00:30<02:07,  4.81it/s]\u001b[A\n",
            "Training:  19% 140/753 [00:30<02:04,  4.91it/s]\u001b[A\n",
            "Training:  19% 141/753 [00:30<02:05,  4.88it/s]\u001b[A\n",
            "Training:  19% 142/753 [00:30<02:05,  4.87it/s]\u001b[A\n",
            "Training:  19% 143/753 [00:31<02:06,  4.84it/s]\u001b[A\n",
            "Training:  19% 144/753 [00:31<02:05,  4.86it/s]\u001b[A\n",
            "Training:  19% 145/753 [00:31<02:11,  4.61it/s]\u001b[A\n",
            "Training:  19% 146/753 [00:31<02:11,  4.62it/s]\u001b[A\n",
            "Training:  20% 147/753 [00:31<02:12,  4.56it/s]\u001b[A\n",
            "Training:  20% 148/753 [00:32<02:11,  4.60it/s]\u001b[A\n",
            "Training:  20% 149/753 [00:32<02:10,  4.65it/s]\u001b[A\n",
            "Training:  20% 150/753 [00:32<02:09,  4.64it/s]\u001b[A\n",
            "Training:  20% 151/753 [00:32<02:07,  4.73it/s]\u001b[A\n",
            "Training:  20% 152/753 [00:33<02:03,  4.87it/s]\u001b[A\n",
            "Training:  20% 153/753 [00:33<02:05,  4.79it/s]\u001b[A\n",
            "Training:  20% 154/753 [00:33<02:02,  4.88it/s]\u001b[A\n",
            "Training:  21% 155/753 [00:33<02:04,  4.81it/s]\u001b[A\n",
            "Training:  21% 156/753 [00:33<02:04,  4.78it/s]\u001b[A\n",
            "Training:  21% 157/753 [00:34<02:06,  4.72it/s]\u001b[A\n",
            "Training:  21% 158/753 [00:34<02:07,  4.67it/s]\u001b[A\n",
            "Training:  21% 159/753 [00:34<02:07,  4.65it/s]\u001b[A\n",
            "Training:  21% 160/753 [00:34<02:09,  4.57it/s]\u001b[A\n",
            "Training:  21% 161/753 [00:34<02:12,  4.45it/s]\u001b[A\n",
            "Training:  22% 162/753 [00:35<02:09,  4.56it/s]\u001b[A\n",
            "Training:  22% 163/753 [00:35<02:06,  4.66it/s]\u001b[A\n",
            "Training:  22% 164/753 [00:35<02:06,  4.65it/s]\u001b[A\n",
            "Training:  22% 165/753 [00:35<02:10,  4.51it/s]\u001b[A\n",
            "Training:  22% 166/753 [00:36<02:07,  4.61it/s]\u001b[A\n",
            "Training:  22% 167/753 [00:36<02:07,  4.59it/s]\u001b[A\n",
            "Training:  22% 168/753 [00:36<02:09,  4.53it/s]\u001b[A\n",
            "Training:  22% 169/753 [00:36<02:08,  4.55it/s]\u001b[A\n",
            "Training:  23% 170/753 [00:36<02:07,  4.57it/s]\u001b[A\n",
            "Training:  23% 171/753 [00:37<02:04,  4.69it/s]\u001b[A\n",
            "Training:  23% 172/753 [00:37<02:00,  4.82it/s]\u001b[A\n",
            "Training:  23% 173/753 [00:37<02:01,  4.75it/s]\u001b[A\n",
            "Training:  23% 174/753 [00:37<01:59,  4.84it/s]\u001b[A\n",
            "Training:  23% 175/753 [00:37<01:58,  4.90it/s]\u001b[A\n",
            "Training:  23% 176/753 [00:38<01:57,  4.93it/s]\u001b[A\n",
            "Training:  24% 177/753 [00:38<02:02,  4.70it/s]\u001b[A\n",
            "Training:  24% 178/753 [00:38<02:01,  4.74it/s]\u001b[A\n",
            "Training:  24% 179/753 [00:38<02:01,  4.72it/s]\u001b[A\n",
            "Training:  24% 180/753 [00:39<02:00,  4.75it/s]\u001b[A\n",
            "Training:  24% 181/753 [00:39<02:01,  4.71it/s]\u001b[A\n",
            "Training:  24% 182/753 [00:39<02:00,  4.73it/s]\u001b[A\n",
            "Training:  24% 183/753 [00:39<01:58,  4.81it/s]\u001b[A\n",
            "Training:  24% 184/753 [00:39<01:57,  4.85it/s]\u001b[A\n",
            "Training:  25% 185/753 [00:40<01:59,  4.77it/s]\u001b[A\n",
            "Training:  25% 186/753 [00:40<01:57,  4.82it/s]\u001b[A\n",
            "Training:  25% 187/753 [00:40<02:01,  4.67it/s]\u001b[A\n",
            "Training:  25% 188/753 [00:40<02:01,  4.65it/s]\u001b[A\n",
            "Training:  25% 189/753 [00:40<02:02,  4.60it/s]\u001b[A\n",
            "Training:  25% 190/753 [00:41<01:59,  4.73it/s]\u001b[A\n",
            "Training:  25% 191/753 [00:41<02:02,  4.57it/s]\u001b[A\n",
            "Training:  25% 192/753 [00:41<02:06,  4.45it/s]\u001b[A\n",
            "Training:  26% 193/753 [00:41<02:04,  4.49it/s]\u001b[A\n",
            "Training:  26% 194/753 [00:42<02:04,  4.47it/s]\u001b[A\n",
            "Training:  26% 195/753 [00:42<02:01,  4.60it/s]\u001b[A\n",
            "Training:  26% 196/753 [00:42<02:00,  4.62it/s]\u001b[A\n",
            "Training:  26% 197/753 [00:42<02:00,  4.62it/s]\u001b[A\n",
            "Training:  26% 198/753 [00:42<01:57,  4.71it/s]\u001b[A\n",
            "Training:  26% 199/753 [00:43<01:56,  4.78it/s]\u001b[A\n",
            "Training:  27% 200/753 [00:43<01:56,  4.75it/s]\u001b[A\n",
            "Training:  27% 201/753 [00:43<01:57,  4.69it/s]\u001b[A\n",
            "Training:  27% 202/753 [00:43<01:55,  4.75it/s]\u001b[A\n",
            "Training:  27% 203/753 [00:43<01:57,  4.68it/s]\u001b[A\n",
            "Training:  27% 204/753 [00:44<01:59,  4.61it/s]\u001b[A\n",
            "Training:  27% 205/753 [00:44<01:54,  4.77it/s]\u001b[A\n",
            "Training:  27% 206/753 [00:44<01:55,  4.73it/s]\u001b[A\n",
            "Training:  27% 207/753 [00:44<02:01,  4.51it/s]\u001b[A\n",
            "Training:  28% 208/753 [00:45<01:57,  4.63it/s]\u001b[A\n",
            "Training:  28% 209/753 [00:45<01:58,  4.58it/s]\u001b[A\n",
            "Training:  28% 210/753 [00:45<01:56,  4.67it/s]\u001b[A\n",
            "Training:  28% 211/753 [00:45<01:54,  4.73it/s]\u001b[A\n",
            "Training:  28% 212/753 [00:45<01:50,  4.88it/s]\u001b[A\n",
            "Training:  28% 213/753 [00:46<01:53,  4.78it/s]\u001b[A\n",
            "Training:  28% 214/753 [00:46<01:53,  4.75it/s]\u001b[A\n",
            "Training:  29% 215/753 [00:46<01:52,  4.79it/s]\u001b[A\n",
            "Training:  29% 216/753 [00:46<01:50,  4.85it/s]\u001b[A\n",
            "Training:  29% 217/753 [00:46<01:49,  4.90it/s]\u001b[A\n",
            "Training:  29% 218/753 [00:47<01:49,  4.89it/s]\u001b[A\n",
            "Training:  29% 219/753 [00:47<01:53,  4.71it/s]\u001b[A\n",
            "Training:  29% 220/753 [00:47<01:51,  4.78it/s]\u001b[A\n",
            "Training:  29% 221/753 [00:47<01:53,  4.67it/s]\u001b[A\n",
            "Training:  29% 222/753 [00:47<01:53,  4.68it/s]\u001b[A\n",
            "Training:  30% 223/753 [00:48<01:52,  4.70it/s]\u001b[A\n",
            "Training:  30% 224/753 [00:48<01:52,  4.70it/s]\u001b[A\n",
            "Training:  30% 225/753 [00:48<01:52,  4.68it/s]\u001b[A\n",
            "Training:  30% 226/753 [00:48<01:51,  4.72it/s]\u001b[A\n",
            "Training:  30% 227/753 [00:49<01:55,  4.55it/s]\u001b[A\n",
            "Training:  30% 228/753 [00:49<02:01,  4.33it/s]\u001b[A\n",
            "Training:  30% 229/753 [00:49<01:59,  4.37it/s]\u001b[A\n",
            "Training:  31% 230/753 [00:49<01:57,  4.46it/s]\u001b[A\n",
            "Training:  31% 231/753 [00:49<01:52,  4.62it/s]\u001b[A\n",
            "Training:  31% 232/753 [00:50<01:49,  4.74it/s]\u001b[A\n",
            "Training:  31% 233/753 [00:50<01:52,  4.60it/s]\u001b[A\n",
            "Training:  31% 234/753 [00:50<01:54,  4.52it/s]\u001b[A\n",
            "Training:  31% 235/753 [00:50<01:54,  4.51it/s]\u001b[A\n",
            "Training:  31% 236/753 [00:51<01:51,  4.64it/s]\u001b[A\n",
            "Training:  31% 237/753 [00:51<01:52,  4.59it/s]\u001b[A\n",
            "Training:  32% 238/753 [00:51<01:52,  4.57it/s]\u001b[A\n",
            "Training:  32% 239/753 [00:51<01:51,  4.60it/s]\u001b[A\n",
            "Training:  32% 240/753 [00:51<01:51,  4.59it/s]\u001b[A\n",
            "Training:  32% 241/753 [00:52<01:57,  4.35it/s]\u001b[A\n",
            "Training:  32% 242/753 [00:52<01:54,  4.45it/s]\u001b[A\n",
            "Training:  32% 243/753 [00:52<01:50,  4.63it/s]\u001b[A\n",
            "Training:  32% 244/753 [00:52<01:52,  4.52it/s]\u001b[A\n",
            "Training:  33% 245/753 [00:53<01:51,  4.54it/s]\u001b[A\n",
            "Training:  33% 246/753 [00:53<01:53,  4.48it/s]\u001b[A\n",
            "Training:  33% 247/753 [00:53<01:49,  4.62it/s]\u001b[A\n",
            "Training:  33% 248/753 [00:53<01:48,  4.63it/s]\u001b[A\n",
            "Training:  33% 249/753 [00:53<01:51,  4.50it/s]\u001b[A\n",
            "Training:  33% 250/753 [00:54<01:49,  4.59it/s]\u001b[A\n",
            "Training:  33% 251/753 [00:54<01:54,  4.37it/s]\u001b[A\n",
            "Training:  33% 252/753 [00:54<01:51,  4.48it/s]\u001b[A\n",
            "Training:  34% 253/753 [00:54<01:51,  4.49it/s]\u001b[A\n",
            "Training:  34% 254/753 [00:54<01:49,  4.54it/s]\u001b[A\n",
            "Training:  34% 255/753 [00:55<01:47,  4.62it/s]\u001b[A\n",
            "Training:  34% 256/753 [00:55<01:47,  4.60it/s]\u001b[A\n",
            "Training:  34% 257/753 [00:55<01:45,  4.72it/s]\u001b[A\n",
            "Training:  34% 258/753 [00:55<01:43,  4.77it/s]\u001b[A\n",
            "Training:  34% 259/753 [00:56<01:42,  4.81it/s]\u001b[A\n",
            "Training:  35% 260/753 [00:56<01:41,  4.86it/s]\u001b[A\n",
            "Training:  35% 261/753 [00:56<01:42,  4.80it/s]\u001b[A\n",
            "Training:  35% 262/753 [00:56<01:41,  4.85it/s]\u001b[A\n",
            "Training:  35% 263/753 [00:56<01:39,  4.93it/s]\u001b[A\n",
            "Training:  35% 264/753 [00:57<01:38,  4.97it/s]\u001b[A\n",
            "Training:  35% 265/753 [00:57<01:39,  4.92it/s]\u001b[A\n",
            "Training:  35% 266/753 [00:57<01:40,  4.87it/s]\u001b[A\n",
            "Training:  35% 267/753 [00:57<01:39,  4.88it/s]\u001b[A\n",
            "Training:  36% 268/753 [00:57<01:38,  4.93it/s]\u001b[A\n",
            "Training:  36% 269/753 [00:58<01:40,  4.82it/s]\u001b[A\n",
            "Training:  36% 270/753 [00:58<01:40,  4.81it/s]\u001b[A\n",
            "Training:  36% 271/753 [00:58<01:40,  4.77it/s]\u001b[A\n",
            "Training:  36% 272/753 [00:58<01:41,  4.73it/s]\u001b[A\n",
            "Training:  36% 273/753 [00:58<01:42,  4.69it/s]\u001b[A\n",
            "Training:  36% 274/753 [00:59<01:42,  4.66it/s]\u001b[A\n",
            "Training:  37% 275/753 [00:59<01:41,  4.73it/s]\u001b[A\n",
            "Training:  37% 276/753 [00:59<01:41,  4.68it/s]\u001b[A\n",
            "Training:  37% 277/753 [00:59<01:39,  4.81it/s]\u001b[A\n",
            "Training:  37% 278/753 [00:59<01:41,  4.67it/s]\u001b[A\n",
            "Training:  37% 279/753 [01:00<01:43,  4.59it/s]\u001b[A\n",
            "Training:  37% 280/753 [01:00<01:39,  4.75it/s]\u001b[A\n",
            "Training:  37% 281/753 [01:00<01:39,  4.75it/s]\u001b[A\n",
            "Training:  37% 282/753 [01:00<01:37,  4.81it/s]\u001b[A\n",
            "Training:  38% 283/753 [01:01<01:36,  4.86it/s]\u001b[A\n",
            "Training:  38% 284/753 [01:01<01:37,  4.80it/s]\u001b[A\n",
            "Training:  38% 285/753 [01:01<01:37,  4.79it/s]\u001b[A\n",
            "Training:  38% 286/753 [01:01<01:41,  4.60it/s]\u001b[A\n",
            "Training:  38% 287/753 [01:01<01:40,  4.62it/s]\u001b[A\n",
            "Training:  38% 288/753 [01:02<01:41,  4.57it/s]\u001b[A\n",
            "Training:  38% 289/753 [01:02<01:41,  4.56it/s]\u001b[A\n",
            "Training:  39% 290/753 [01:02<01:39,  4.66it/s]\u001b[A\n",
            "Training:  39% 291/753 [01:02<01:38,  4.67it/s]\u001b[A\n",
            "Training:  39% 292/753 [01:02<01:38,  4.67it/s]\u001b[A\n",
            "Training:  39% 293/753 [01:03<01:37,  4.71it/s]\u001b[A\n",
            "Training:  39% 294/753 [01:03<01:38,  4.67it/s]\u001b[A\n",
            "Training:  39% 295/753 [01:03<01:40,  4.53it/s]\u001b[A\n",
            "Training:  39% 296/753 [01:03<01:38,  4.66it/s]\u001b[A\n",
            "Training:  39% 297/753 [01:04<01:40,  4.52it/s]\u001b[A\n",
            "Training:  40% 298/753 [01:04<01:40,  4.54it/s]\u001b[A\n",
            "Training:  40% 299/753 [01:04<01:37,  4.65it/s]\u001b[A\n",
            "Training:  40% 300/753 [01:04<01:39,  4.58it/s]\u001b[A\n",
            "Training:  40% 301/753 [01:04<01:40,  4.51it/s]\u001b[A\n",
            "Training:  40% 302/753 [01:05<01:39,  4.54it/s]\u001b[A\n",
            "Training:  40% 303/753 [01:05<01:42,  4.41it/s]\u001b[A\n",
            "Training:  40% 304/753 [01:05<01:39,  4.49it/s]\u001b[A\n",
            "Training:  41% 305/753 [01:05<01:39,  4.51it/s]\u001b[A\n",
            "Training:  41% 306/753 [01:06<01:41,  4.42it/s]\u001b[A\n",
            "Training:  41% 307/753 [01:06<01:40,  4.42it/s]\u001b[A\n",
            "Training:  41% 308/753 [01:06<01:36,  4.60it/s]\u001b[A\n",
            "Training:  41% 309/753 [01:06<01:34,  4.68it/s]\u001b[A\n",
            "Training:  41% 310/753 [01:06<01:33,  4.74it/s]\u001b[A\n",
            "Training:  41% 311/753 [01:07<01:31,  4.81it/s]\u001b[A\n",
            "Training:  41% 312/753 [01:07<01:31,  4.85it/s]\u001b[A\n",
            "Training:  42% 313/753 [01:07<01:31,  4.81it/s]\u001b[A\n",
            "Training:  42% 314/753 [01:07<01:33,  4.69it/s]\u001b[A\n",
            "Training:  42% 315/753 [01:07<01:32,  4.73it/s]\u001b[A\n",
            "Training:  42% 316/753 [01:08<01:33,  4.68it/s]\u001b[A\n",
            "Training:  42% 317/753 [01:08<01:32,  4.72it/s]\u001b[A\n",
            "Training:  42% 318/753 [01:08<01:31,  4.74it/s]\u001b[A\n",
            "Training:  42% 319/753 [01:08<01:30,  4.78it/s]\u001b[A\n",
            "Training:  42% 320/753 [01:09<01:32,  4.69it/s]\u001b[A\n",
            "Training:  43% 321/753 [01:09<01:32,  4.69it/s]\u001b[A\n",
            "Training:  43% 322/753 [01:09<01:31,  4.71it/s]\u001b[A\n",
            "Training:  43% 323/753 [01:09<01:29,  4.83it/s]\u001b[A\n",
            "Training:  43% 324/753 [01:09<01:27,  4.93it/s]\u001b[A\n",
            "Training:  43% 325/753 [01:10<01:25,  4.98it/s]\u001b[A\n",
            "Training:  43% 326/753 [01:10<01:25,  4.97it/s]\u001b[A\n",
            "Training:  43% 327/753 [01:10<01:26,  4.94it/s]\u001b[A\n",
            "Training:  44% 328/753 [01:10<01:29,  4.75it/s]\u001b[A\n",
            "Training:  44% 329/753 [01:10<01:31,  4.63it/s]\u001b[A\n",
            "Training:  44% 330/753 [01:11<01:30,  4.67it/s]\u001b[A\n",
            "Training:  44% 331/753 [01:11<01:28,  4.80it/s]\u001b[A\n",
            "Training:  44% 332/753 [01:11<01:28,  4.78it/s]\u001b[A\n",
            "Training:  44% 333/753 [01:11<01:28,  4.76it/s]\u001b[A\n",
            "Training:  44% 334/753 [01:11<01:31,  4.60it/s]\u001b[A\n",
            "Training:  44% 335/753 [01:12<01:31,  4.58it/s]\u001b[A\n",
            "Training:  45% 336/753 [01:12<01:32,  4.51it/s]\u001b[A\n",
            "Training:  45% 337/753 [01:12<01:29,  4.63it/s]\u001b[A\n",
            "Training:  45% 338/753 [01:12<01:27,  4.72it/s]\u001b[A\n",
            "Training:  45% 339/753 [01:13<01:27,  4.71it/s]\u001b[A\n",
            "Training:  45% 340/753 [01:13<01:27,  4.74it/s]\u001b[A\n",
            "Training:  45% 341/753 [01:13<01:27,  4.70it/s]\u001b[A\n",
            "Training:  45% 342/753 [01:13<01:28,  4.65it/s]\u001b[A\n",
            "Training:  46% 343/753 [01:13<01:26,  4.73it/s]\u001b[A\n",
            "Training:  46% 344/753 [01:14<01:27,  4.68it/s]\u001b[A\n",
            "Training:  46% 345/753 [01:14<01:27,  4.65it/s]\u001b[A\n",
            "Training:  46% 346/753 [01:14<01:24,  4.79it/s]\u001b[A\n",
            "Training:  46% 347/753 [01:14<01:27,  4.67it/s]\u001b[A\n",
            "Training:  46% 348/753 [01:14<01:25,  4.76it/s]\u001b[A\n",
            "Training:  46% 349/753 [01:15<01:26,  4.69it/s]\u001b[A\n",
            "Training:  46% 350/753 [01:15<01:27,  4.60it/s]\u001b[A\n",
            "Training:  47% 351/753 [01:15<01:26,  4.66it/s]\u001b[A\n",
            "Training:  47% 352/753 [01:15<01:25,  4.69it/s]\u001b[A\n",
            "Training:  47% 353/753 [01:16<01:24,  4.72it/s]\u001b[A\n",
            "Training:  47% 354/753 [01:16<01:23,  4.79it/s]\u001b[A\n",
            "Training:  47% 355/753 [01:16<01:21,  4.86it/s]\u001b[A\n",
            "Training:  47% 356/753 [01:16<01:21,  4.85it/s]\u001b[A\n",
            "Training:  47% 357/753 [01:16<01:21,  4.85it/s]\u001b[A\n",
            "Training:  48% 358/753 [01:17<01:19,  4.96it/s]\u001b[A\n",
            "Training:  48% 359/753 [01:17<01:21,  4.81it/s]\u001b[A\n",
            "Training:  48% 360/753 [01:17<01:22,  4.77it/s]\u001b[A\n",
            "Training:  48% 361/753 [01:17<01:24,  4.65it/s]\u001b[A\n",
            "Training:  48% 362/753 [01:17<01:23,  4.67it/s]\u001b[A\n",
            "Training:  48% 363/753 [01:18<01:25,  4.58it/s]\u001b[A\n",
            "Training:  48% 364/753 [01:18<01:26,  4.50it/s]\u001b[A\n",
            "Training:  48% 365/753 [01:18<01:25,  4.55it/s]\u001b[A\n",
            "Training:  49% 366/753 [01:18<01:24,  4.58it/s]\u001b[A\n",
            "Training:  49% 367/753 [01:18<01:23,  4.60it/s]\u001b[A\n",
            "Training:  49% 368/753 [01:19<01:24,  4.58it/s]\u001b[A\n",
            "Training:  49% 369/753 [01:19<01:23,  4.62it/s]\u001b[A\n",
            "Training:  49% 370/753 [01:19<01:23,  4.60it/s]\u001b[A\n",
            "Training:  49% 371/753 [01:19<01:21,  4.70it/s]\u001b[A\n",
            "Training:  49% 372/753 [01:20<01:20,  4.74it/s]\u001b[A\n",
            "Training:  50% 373/753 [01:20<01:22,  4.62it/s]\u001b[A\n",
            "Training:  50% 374/753 [01:20<01:21,  4.67it/s]\u001b[A\n",
            "Training:  50% 375/753 [01:20<01:22,  4.61it/s]\u001b[A\n",
            "Training:  50% 376/753 [01:20<01:21,  4.61it/s]\u001b[A\n",
            "Training:  50% 377/753 [01:21<01:21,  4.59it/s]\u001b[A\n",
            "Training:  50% 378/753 [01:21<01:21,  4.58it/s]\u001b[A\n",
            "Training:  50% 379/753 [01:21<01:20,  4.65it/s]\u001b[A\n",
            "Training:  50% 380/753 [01:21<01:19,  4.67it/s]\u001b[A\n",
            "Training:  51% 381/753 [01:22<01:22,  4.52it/s]\u001b[A\n",
            "Training:  51% 382/753 [01:22<01:21,  4.58it/s]\u001b[A\n",
            "Training:  51% 383/753 [01:22<01:21,  4.53it/s]\u001b[A\n",
            "Training:  51% 384/753 [01:22<01:20,  4.60it/s]\u001b[A\n",
            "Training:  51% 385/753 [01:22<01:17,  4.74it/s]\u001b[A\n",
            "Training:  51% 386/753 [01:23<01:19,  4.63it/s]\u001b[A\n",
            "Training:  51% 387/753 [01:23<01:19,  4.60it/s]\u001b[A\n",
            "Training:  52% 388/753 [01:23<01:18,  4.68it/s]\u001b[A\n",
            "Training:  52% 389/753 [01:23<01:16,  4.73it/s]\u001b[A\n",
            "Training:  52% 390/753 [01:23<01:15,  4.80it/s]\u001b[A\n",
            "Training:  52% 391/753 [01:24<01:16,  4.73it/s]\u001b[A\n",
            "Training:  52% 392/753 [01:24<01:16,  4.72it/s]\u001b[A\n",
            "Training:  52% 393/753 [01:24<01:16,  4.68it/s]\u001b[A\n",
            "Training:  52% 394/753 [01:24<01:18,  4.56it/s]\u001b[A\n",
            "Training:  52% 395/753 [01:25<01:16,  4.69it/s]\u001b[A\n",
            "Training:  53% 396/753 [01:25<01:17,  4.64it/s]\u001b[A\n",
            "Training:  53% 397/753 [01:25<01:15,  4.72it/s]\u001b[A\n",
            "Training:  53% 398/753 [01:25<01:14,  4.74it/s]\u001b[A\n",
            "Training:  53% 399/753 [01:25<01:14,  4.72it/s]\u001b[A\n",
            "Training:  53% 400/753 [01:26<01:12,  4.84it/s]\u001b[A\n",
            "Training:  53% 401/753 [01:26<01:14,  4.72it/s]\u001b[A\n",
            "Training:  53% 402/753 [01:26<01:13,  4.75it/s]\u001b[A\n",
            "Training:  54% 403/753 [01:26<01:13,  4.78it/s]\u001b[A\n",
            "Training:  54% 404/753 [01:26<01:14,  4.71it/s]\u001b[A\n",
            "Training:  54% 405/753 [01:27<01:12,  4.78it/s]\u001b[A\n",
            "Training:  54% 406/753 [01:27<01:13,  4.73it/s]\u001b[A\n",
            "Training:  54% 407/753 [01:27<01:13,  4.71it/s]\u001b[A\n",
            "Training:  54% 408/753 [01:27<01:13,  4.72it/s]\u001b[A\n",
            "Training:  54% 409/753 [01:27<01:13,  4.69it/s]\u001b[A\n",
            "Training:  54% 410/753 [01:28<01:10,  4.84it/s]\u001b[A\n",
            "Training:  55% 411/753 [01:28<01:10,  4.86it/s]\u001b[A\n",
            "Training:  55% 412/753 [01:28<01:14,  4.60it/s]\u001b[A\n",
            "Training:  55% 413/753 [01:28<01:16,  4.43it/s]\u001b[A\n",
            "Training:  55% 414/753 [01:29<01:14,  4.53it/s]\u001b[A\n",
            "Training:  55% 415/753 [01:29<01:14,  4.56it/s]\u001b[A\n",
            "Training:  55% 416/753 [01:29<01:13,  4.60it/s]\u001b[A\n",
            "Training:  55% 417/753 [01:29<01:12,  4.63it/s]\u001b[A\n",
            "Training:  56% 418/753 [01:29<01:11,  4.67it/s]\u001b[A\n",
            "Training:  56% 419/753 [01:30<01:12,  4.62it/s]\u001b[A\n",
            "Training:  56% 420/753 [01:30<01:12,  4.59it/s]\u001b[A\n",
            "Training:  56% 421/753 [01:30<01:10,  4.71it/s]\u001b[A\n",
            "Training:  56% 422/753 [01:30<01:10,  4.69it/s]\u001b[A\n",
            "Training:  56% 423/753 [01:30<01:10,  4.69it/s]\u001b[A\n",
            "Training:  56% 424/753 [01:31<01:11,  4.57it/s]\u001b[A\n",
            "Training:  56% 425/753 [01:31<01:10,  4.66it/s]\u001b[A\n",
            "Training:  57% 426/753 [01:31<01:08,  4.78it/s]\u001b[A\n",
            "Training:  57% 427/753 [01:31<01:09,  4.70it/s]\u001b[A\n",
            "Training:  57% 428/753 [01:32<01:08,  4.72it/s]\u001b[A\n",
            "Training:  57% 429/753 [01:32<01:08,  4.70it/s]\u001b[A\n",
            "Training:  57% 430/753 [01:32<01:10,  4.58it/s]\u001b[A\n",
            "Training:  57% 431/753 [01:32<01:09,  4.64it/s]\u001b[A\n",
            "Training:  57% 432/753 [01:32<01:08,  4.67it/s]\u001b[A\n",
            "Training:  58% 433/753 [01:33<01:08,  4.65it/s]\u001b[A\n",
            "Training:  58% 434/753 [01:33<01:09,  4.62it/s]\u001b[A\n",
            "Training:  58% 435/753 [01:33<01:08,  4.62it/s]\u001b[A\n",
            "Training:  58% 436/753 [01:33<01:08,  4.66it/s]\u001b[A\n",
            "Training:  58% 437/753 [01:34<01:08,  4.60it/s]\u001b[A\n",
            "Training:  58% 438/753 [01:34<01:08,  4.63it/s]\u001b[A\n",
            "Training:  58% 439/753 [01:34<01:07,  4.65it/s]\u001b[A\n",
            "Training:  58% 440/753 [01:34<01:07,  4.63it/s]\u001b[A\n",
            "Training:  59% 441/753 [01:34<01:07,  4.60it/s]\u001b[A\n",
            "Training:  59% 442/753 [01:35<01:07,  4.61it/s]\u001b[A\n",
            "Training:  59% 443/753 [01:35<01:07,  4.58it/s]\u001b[A\n",
            "Training:  59% 444/753 [01:35<01:07,  4.57it/s]\u001b[A\n",
            "Training:  59% 445/753 [01:35<01:08,  4.53it/s]\u001b[A\n",
            "Training:  59% 446/753 [01:35<01:05,  4.65it/s]\u001b[A\n",
            "Training:  59% 447/753 [01:36<01:05,  4.68it/s]\u001b[A\n",
            "Training:  59% 448/753 [01:36<01:05,  4.68it/s]\u001b[A\n",
            "Training:  60% 449/753 [01:36<01:05,  4.64it/s]\u001b[A\n",
            "Training:  60% 450/753 [01:36<01:03,  4.75it/s]\u001b[A\n",
            "Training:  60% 451/753 [01:36<01:02,  4.87it/s]\u001b[A\n",
            "Training:  60% 452/753 [01:37<01:02,  4.83it/s]\u001b[A\n",
            "Training:  60% 453/753 [01:37<01:03,  4.72it/s]\u001b[A\n",
            "Training:  60% 454/753 [01:37<01:05,  4.55it/s]\u001b[A\n",
            "Training:  60% 455/753 [01:37<01:04,  4.60it/s]\u001b[A\n",
            "Training:  61% 456/753 [01:38<01:06,  4.48it/s]\u001b[A\n",
            "Training:  61% 457/753 [01:38<01:06,  4.46it/s]\u001b[A\n",
            "Training:  61% 458/753 [01:38<01:03,  4.67it/s]\u001b[A\n",
            "Training:  61% 459/753 [01:38<01:04,  4.57it/s]\u001b[A\n",
            "Training:  61% 460/753 [01:38<01:04,  4.52it/s]\u001b[A\n",
            "Training:  61% 461/753 [01:39<01:03,  4.58it/s]\u001b[A\n",
            "Training:  61% 462/753 [01:39<01:04,  4.55it/s]\u001b[A\n",
            "Training:  61% 463/753 [01:39<01:05,  4.40it/s]\u001b[A\n",
            "Training:  62% 464/753 [01:39<01:04,  4.51it/s]\u001b[A\n",
            "Training:  62% 465/753 [01:40<01:04,  4.45it/s]\u001b[A\n",
            "Training:  62% 466/753 [01:40<01:04,  4.47it/s]\u001b[A\n",
            "Training:  62% 467/753 [01:40<01:04,  4.41it/s]\u001b[A\n",
            "Training:  62% 468/753 [01:40<01:02,  4.55it/s]\u001b[A\n",
            "Training:  62% 469/753 [01:40<01:02,  4.57it/s]\u001b[A\n",
            "Training:  62% 470/753 [01:41<01:00,  4.66it/s]\u001b[A\n",
            "Training:  63% 471/753 [01:41<01:00,  4.69it/s]\u001b[A\n",
            "Training:  63% 472/753 [01:41<01:00,  4.67it/s]\u001b[A\n",
            "Training:  63% 473/753 [01:41<00:59,  4.67it/s]\u001b[A\n",
            "Training:  63% 474/753 [01:42<01:00,  4.63it/s]\u001b[A\n",
            "Training:  63% 475/753 [01:42<01:00,  4.57it/s]\u001b[A\n",
            "Training:  63% 476/753 [01:42<01:00,  4.58it/s]\u001b[A\n",
            "Training:  63% 477/753 [01:42<00:59,  4.61it/s]\u001b[A\n",
            "Training:  63% 478/753 [01:42<01:01,  4.49it/s]\u001b[A\n",
            "Training:  64% 479/753 [01:43<01:01,  4.48it/s]\u001b[A\n",
            "Training:  64% 480/753 [01:43<01:00,  4.52it/s]\u001b[A\n",
            "Training:  64% 481/753 [01:43<01:00,  4.47it/s]\u001b[A\n",
            "Training:  64% 482/753 [01:43<01:00,  4.52it/s]\u001b[A\n",
            "Training:  64% 483/753 [01:44<00:58,  4.61it/s]\u001b[A\n",
            "Training:  64% 484/753 [01:44<00:59,  4.49it/s]\u001b[A\n",
            "Training:  64% 485/753 [01:44<00:59,  4.51it/s]\u001b[A\n",
            "Training:  65% 486/753 [01:44<00:58,  4.53it/s]\u001b[A\n",
            "Training:  65% 487/753 [01:44<00:58,  4.59it/s]\u001b[A\n",
            "Training:  65% 488/753 [01:45<00:59,  4.46it/s]\u001b[A\n",
            "Training:  65% 489/753 [01:45<00:58,  4.53it/s]\u001b[A\n",
            "Training:  65% 490/753 [01:45<00:56,  4.66it/s]\u001b[A\n",
            "Training:  65% 491/753 [01:45<00:54,  4.78it/s]\u001b[A\n",
            "Training:  65% 492/753 [01:46<00:55,  4.66it/s]\u001b[A\n",
            "Training:  65% 493/753 [01:46<00:56,  4.62it/s]\u001b[A\n",
            "Training:  66% 494/753 [01:46<00:55,  4.66it/s]\u001b[A\n",
            "Training:  66% 495/753 [01:46<00:55,  4.61it/s]\u001b[A\n",
            "Training:  66% 496/753 [01:46<00:54,  4.72it/s]\u001b[A\n",
            "Training:  66% 497/753 [01:47<00:54,  4.67it/s]\u001b[A\n",
            "Training:  66% 498/753 [01:47<00:54,  4.71it/s]\u001b[A\n",
            "Training:  66% 499/753 [01:47<00:54,  4.65it/s]\u001b[A\n",
            "Training:  66% 500/753 [01:47<00:52,  4.85it/s]\u001b[A\n",
            "Training:  67% 501/753 [01:47<00:53,  4.75it/s]\u001b[A\n",
            "Training:  67% 502/753 [01:48<00:53,  4.66it/s]\u001b[A\n",
            "Training:  67% 503/753 [01:48<00:54,  4.60it/s]\u001b[A\n",
            "Training:  67% 504/753 [01:48<00:53,  4.69it/s]\u001b[A\n",
            "Training:  67% 505/753 [01:48<00:52,  4.72it/s]\u001b[A\n",
            "Training:  67% 506/753 [01:48<00:52,  4.67it/s]\u001b[A\n",
            "Training:  67% 507/753 [01:49<00:54,  4.54it/s]\u001b[A\n",
            "Training:  67% 508/753 [01:49<00:53,  4.57it/s]\u001b[A\n",
            "Training:  68% 509/753 [01:49<00:52,  4.61it/s]\u001b[A\n",
            "Training:  68% 510/753 [01:49<00:52,  4.67it/s]\u001b[A\n",
            "Training:  68% 511/753 [01:50<00:51,  4.72it/s]\u001b[A\n",
            "Training:  68% 512/753 [01:50<00:51,  4.68it/s]\u001b[A\n",
            "Training:  68% 513/753 [01:50<00:49,  4.80it/s]\u001b[A\n",
            "Training:  68% 514/753 [01:50<00:50,  4.77it/s]\u001b[A\n",
            "Training:  68% 515/753 [01:50<00:49,  4.80it/s]\u001b[A\n",
            "Training:  69% 516/753 [01:51<00:50,  4.68it/s]\u001b[A\n",
            "Training:  69% 517/753 [01:51<00:49,  4.76it/s]\u001b[A\n",
            "Training:  69% 518/753 [01:51<00:50,  4.63it/s]\u001b[A\n",
            "Training:  69% 519/753 [01:51<00:49,  4.75it/s]\u001b[A\n",
            "Training:  69% 520/753 [01:51<00:47,  4.86it/s]\u001b[A\n",
            "Training:  69% 521/753 [01:52<00:46,  4.99it/s]\u001b[A\n",
            "Training:  69% 522/753 [01:52<00:47,  4.87it/s]\u001b[A\n",
            "Training:  69% 523/753 [01:52<00:45,  5.02it/s]\u001b[A\n",
            "Training:  70% 524/753 [01:52<00:46,  4.89it/s]\u001b[A\n",
            "Training:  70% 525/753 [01:52<00:47,  4.84it/s]\u001b[A\n",
            "Training:  70% 526/753 [01:53<00:47,  4.74it/s]\u001b[A\n",
            "Training:  70% 527/753 [01:53<00:47,  4.72it/s]\u001b[A\n",
            "Training:  70% 528/753 [01:53<00:47,  4.71it/s]\u001b[A\n",
            "Training:  70% 529/753 [01:53<00:47,  4.73it/s]\u001b[A\n",
            "Training:  70% 530/753 [01:54<00:47,  4.68it/s]\u001b[A\n",
            "Training:  71% 531/753 [01:54<00:48,  4.54it/s]\u001b[A\n",
            "Training:  71% 532/753 [01:54<00:47,  4.66it/s]\u001b[A\n",
            "Training:  71% 533/753 [01:54<00:46,  4.69it/s]\u001b[A\n",
            "Training:  71% 534/753 [01:54<00:46,  4.70it/s]\u001b[A\n",
            "Training:  71% 535/753 [01:55<00:46,  4.65it/s]\u001b[A\n",
            "Training:  71% 536/753 [01:55<00:46,  4.68it/s]\u001b[A\n",
            "Training:  71% 537/753 [01:55<00:45,  4.73it/s]\u001b[A\n",
            "Training:  71% 538/753 [01:55<00:45,  4.72it/s]\u001b[A\n",
            "Training:  72% 539/753 [01:55<00:45,  4.68it/s]\u001b[A\n",
            "Training:  72% 540/753 [01:56<00:45,  4.68it/s]\u001b[A\n",
            "Training:  72% 541/753 [01:56<00:45,  4.71it/s]\u001b[A\n",
            "Training:  72% 542/753 [01:56<00:44,  4.69it/s]\u001b[A\n",
            "Training:  72% 543/753 [01:56<00:43,  4.84it/s]\u001b[A\n",
            "Training:  72% 544/753 [01:57<00:43,  4.77it/s]\u001b[A\n",
            "Training:  72% 545/753 [01:57<00:43,  4.78it/s]\u001b[A\n",
            "Training:  73% 546/753 [01:57<00:42,  4.84it/s]\u001b[A\n",
            "Training:  73% 547/753 [01:57<00:42,  4.83it/s]\u001b[A\n",
            "Training:  73% 548/753 [01:57<00:43,  4.76it/s]\u001b[A\n",
            "Training:  73% 549/753 [01:58<00:43,  4.74it/s]\u001b[A\n",
            "Training:  73% 550/753 [01:58<00:42,  4.72it/s]\u001b[A\n",
            "Training:  73% 551/753 [01:58<00:43,  4.61it/s]\u001b[A\n",
            "Training:  73% 552/753 [01:58<00:42,  4.69it/s]\u001b[A\n",
            "Training:  73% 553/753 [01:58<00:42,  4.70it/s]\u001b[A\n",
            "Training:  74% 554/753 [01:59<00:42,  4.71it/s]\u001b[A\n",
            "Training:  74% 555/753 [01:59<00:42,  4.68it/s]\u001b[A\n",
            "Training:  74% 556/753 [01:59<00:40,  4.82it/s]\u001b[A\n",
            "Training:  74% 557/753 [01:59<00:40,  4.82it/s]\u001b[A\n",
            "Training:  74% 558/753 [01:59<00:41,  4.74it/s]\u001b[A\n",
            "Training:  74% 559/753 [02:00<00:42,  4.59it/s]\u001b[A\n",
            "Training:  74% 560/753 [02:00<00:41,  4.60it/s]\u001b[A\n",
            "Training:  75% 561/753 [02:00<00:40,  4.78it/s]\u001b[A\n",
            "Training:  75% 562/753 [02:00<00:39,  4.79it/s]\u001b[A\n",
            "Training:  75% 563/753 [02:01<00:40,  4.70it/s]\u001b[A\n",
            "Training:  75% 564/753 [02:01<00:40,  4.63it/s]\u001b[A\n",
            "Training:  75% 565/753 [02:01<00:40,  4.67it/s]\u001b[A\n",
            "Training:  75% 566/753 [02:01<00:39,  4.72it/s]\u001b[A\n",
            "Training:  75% 567/753 [02:01<00:38,  4.83it/s]\u001b[A\n",
            "Training:  75% 568/753 [02:02<00:38,  4.82it/s]\u001b[A\n",
            "Training:  76% 569/753 [02:02<00:38,  4.80it/s]\u001b[A\n",
            "Training:  76% 570/753 [02:02<00:37,  4.87it/s]\u001b[A\n",
            "Training:  76% 571/753 [02:02<00:37,  4.81it/s]\u001b[A\n",
            "Training:  76% 572/753 [02:02<00:38,  4.75it/s]\u001b[A\n",
            "Training:  76% 573/753 [02:03<00:36,  4.88it/s]\u001b[A\n",
            "Training:  76% 574/753 [02:03<00:36,  4.85it/s]\u001b[A\n",
            "Training:  76% 575/753 [02:03<00:37,  4.79it/s]\u001b[A\n",
            "Training:  76% 576/753 [02:03<00:37,  4.76it/s]\u001b[A\n",
            "Training:  77% 577/753 [02:03<00:37,  4.71it/s]\u001b[A\n",
            "Training:  77% 578/753 [02:04<00:37,  4.64it/s]\u001b[A\n",
            "Training:  77% 579/753 [02:04<00:37,  4.68it/s]\u001b[A\n",
            "Training:  77% 580/753 [02:04<00:36,  4.75it/s]\u001b[A\n",
            "Training:  77% 581/753 [02:04<00:36,  4.65it/s]\u001b[A\n",
            "Training:  77% 582/753 [02:05<00:37,  4.57it/s]\u001b[A\n",
            "Training:  77% 583/753 [02:05<00:36,  4.63it/s]\u001b[A\n",
            "Training:  78% 584/753 [02:05<00:38,  4.41it/s]\u001b[A\n",
            "Training:  78% 585/753 [02:05<00:37,  4.54it/s]\u001b[A\n",
            "Training:  78% 586/753 [02:05<00:36,  4.58it/s]\u001b[A\n",
            "Training:  78% 587/753 [02:06<00:36,  4.54it/s]\u001b[A\n",
            "Training:  78% 588/753 [02:06<00:35,  4.64it/s]\u001b[A\n",
            "Training:  78% 589/753 [02:06<00:35,  4.61it/s]\u001b[A\n",
            "Training:  78% 590/753 [02:06<00:35,  4.53it/s]\u001b[A\n",
            "Training:  78% 591/753 [02:07<00:35,  4.58it/s]\u001b[A\n",
            "Training:  79% 592/753 [02:07<00:35,  4.59it/s]\u001b[A\n",
            "Training:  79% 593/753 [02:07<00:34,  4.65it/s]\u001b[A\n",
            "Training:  79% 594/753 [02:07<00:34,  4.57it/s]\u001b[A\n",
            "Training:  79% 595/753 [02:07<00:33,  4.66it/s]\u001b[A\n",
            "Training:  79% 596/753 [02:08<00:33,  4.68it/s]\u001b[A\n",
            "Training:  79% 597/753 [02:08<00:33,  4.61it/s]\u001b[A\n",
            "Training:  79% 598/753 [02:08<00:33,  4.56it/s]\u001b[A\n",
            "Training:  80% 599/753 [02:08<00:33,  4.57it/s]\u001b[A\n",
            "Training:  80% 600/753 [02:08<00:33,  4.61it/s]\u001b[A\n",
            "Training:  80% 601/753 [02:09<00:32,  4.65it/s]\u001b[A\n",
            "Training:  80% 602/753 [02:09<00:31,  4.73it/s]\u001b[A\n",
            "Training:  80% 603/753 [02:09<00:31,  4.80it/s]\u001b[A\n",
            "Training:  80% 604/753 [02:09<00:31,  4.78it/s]\u001b[A\n",
            "Training:  80% 605/753 [02:10<00:31,  4.69it/s]\u001b[A\n",
            "Training:  80% 606/753 [02:10<00:31,  4.73it/s]\u001b[A\n",
            "Training:  81% 607/753 [02:10<00:30,  4.71it/s]\u001b[A\n",
            "Training:  81% 608/753 [02:10<00:30,  4.72it/s]\u001b[A\n",
            "Training:  81% 609/753 [02:10<00:30,  4.70it/s]\u001b[A\n",
            "Training:  81% 610/753 [02:11<00:30,  4.63it/s]\u001b[A\n",
            "Training:  81% 611/753 [02:11<00:30,  4.64it/s]\u001b[A\n",
            "Training:  81% 612/753 [02:11<00:29,  4.72it/s]\u001b[A\n",
            "Training:  81% 613/753 [02:11<00:29,  4.70it/s]\u001b[A\n",
            "Training:  82% 614/753 [02:11<00:30,  4.53it/s]\u001b[A\n",
            "Training:  82% 615/753 [02:12<00:30,  4.59it/s]\u001b[A\n",
            "Training:  82% 616/753 [02:12<00:30,  4.51it/s]\u001b[A\n",
            "Training:  82% 617/753 [02:12<00:28,  4.72it/s]\u001b[A\n",
            "Training:  82% 618/753 [02:12<00:27,  4.92it/s]\u001b[A\n",
            "Training:  82% 619/753 [02:13<00:28,  4.64it/s]\u001b[A\n",
            "Training:  82% 620/753 [02:13<00:28,  4.68it/s]\u001b[A\n",
            "Training:  82% 621/753 [02:13<00:28,  4.70it/s]\u001b[A\n",
            "Training:  83% 622/753 [02:13<00:28,  4.65it/s]\u001b[A\n",
            "Training:  83% 623/753 [02:13<00:27,  4.66it/s]\u001b[A\n",
            "Training:  83% 624/753 [02:14<00:27,  4.63it/s]\u001b[A\n",
            "Training:  83% 625/753 [02:14<00:26,  4.79it/s]\u001b[A\n",
            "Training:  83% 626/753 [02:14<00:27,  4.61it/s]\u001b[A\n",
            "Training:  83% 627/753 [02:14<00:27,  4.65it/s]\u001b[A\n",
            "Training:  83% 628/753 [02:14<00:26,  4.67it/s]\u001b[A\n",
            "Training:  84% 629/753 [02:15<00:26,  4.70it/s]\u001b[A\n",
            "Training:  84% 630/753 [02:15<00:26,  4.67it/s]\u001b[A\n",
            "Training:  84% 631/753 [02:15<00:25,  4.82it/s]\u001b[A\n",
            "Training:  84% 632/753 [02:15<00:25,  4.69it/s]\u001b[A\n",
            "Training:  84% 633/753 [02:16<00:25,  4.74it/s]\u001b[A\n",
            "Training:  84% 634/753 [02:16<00:25,  4.63it/s]\u001b[A\n",
            "Training:  84% 635/753 [02:16<00:25,  4.56it/s]\u001b[A\n",
            "Training:  84% 636/753 [02:16<00:25,  4.59it/s]\u001b[A\n",
            "Training:  85% 637/753 [02:16<00:25,  4.57it/s]\u001b[A\n",
            "Training:  85% 638/753 [02:17<00:24,  4.69it/s]\u001b[A\n",
            "Training:  85% 639/753 [02:17<00:23,  4.81it/s]\u001b[A\n",
            "Training:  85% 640/753 [02:17<00:23,  4.81it/s]\u001b[A\n",
            "Training:  85% 641/753 [02:17<00:23,  4.75it/s]\u001b[A\n",
            "Training:  85% 642/753 [02:17<00:22,  4.88it/s]\u001b[A\n",
            "Training:  85% 643/753 [02:18<00:23,  4.68it/s]\u001b[A\n",
            "Training:  86% 644/753 [02:18<00:23,  4.72it/s]\u001b[A\n",
            "Training:  86% 645/753 [02:18<00:22,  4.75it/s]\u001b[A\n",
            "Training:  86% 646/753 [02:18<00:22,  4.75it/s]\u001b[A\n",
            "Training:  86% 647/753 [02:18<00:22,  4.75it/s]\u001b[A\n",
            "Training:  86% 648/753 [02:19<00:22,  4.67it/s]\u001b[A\n",
            "Training:  86% 649/753 [02:19<00:22,  4.68it/s]\u001b[A\n",
            "Training:  86% 650/753 [02:19<00:22,  4.67it/s]\u001b[A\n",
            "Training:  86% 651/753 [02:19<00:21,  4.66it/s]\u001b[A\n",
            "Training:  87% 652/753 [02:20<00:21,  4.76it/s]\u001b[A\n",
            "Training:  87% 653/753 [02:20<00:21,  4.75it/s]\u001b[A\n",
            "Training:  87% 654/753 [02:20<00:21,  4.53it/s]\u001b[A\n",
            "Training:  87% 655/753 [02:20<00:21,  4.59it/s]\u001b[A\n",
            "Training:  87% 656/753 [02:20<00:21,  4.56it/s]\u001b[A\n",
            "Training:  87% 657/753 [02:21<00:21,  4.55it/s]\u001b[A\n",
            "Training:  87% 658/753 [02:21<00:20,  4.61it/s]\u001b[A\n",
            "Training:  88% 659/753 [02:21<00:20,  4.65it/s]\u001b[A\n",
            "Training:  88% 660/753 [02:21<00:20,  4.64it/s]\u001b[A\n",
            "Training:  88% 661/753 [02:22<00:19,  4.62it/s]\u001b[A\n",
            "Training:  88% 662/753 [02:22<00:19,  4.61it/s]\u001b[A\n",
            "Training:  88% 663/753 [02:22<00:19,  4.59it/s]\u001b[A\n",
            "Training:  88% 664/753 [02:22<00:19,  4.65it/s]\u001b[A\n",
            "Training:  88% 665/753 [02:22<00:18,  4.66it/s]\u001b[A\n",
            "Training:  88% 666/753 [02:23<00:18,  4.65it/s]\u001b[A\n",
            "Training:  89% 667/753 [02:23<00:18,  4.61it/s]\u001b[A\n",
            "Training:  89% 668/753 [02:23<00:18,  4.62it/s]\u001b[A\n",
            "Training:  89% 669/753 [02:23<00:18,  4.56it/s]\u001b[A\n",
            "Training:  89% 670/753 [02:23<00:18,  4.55it/s]\u001b[A\n",
            "Training:  89% 671/753 [02:24<00:18,  4.52it/s]\u001b[A\n",
            "Training:  89% 672/753 [02:24<00:17,  4.69it/s]\u001b[A\n",
            "Training:  89% 673/753 [02:24<00:16,  4.75it/s]\u001b[A\n",
            "Training:  90% 674/753 [02:24<00:16,  4.68it/s]\u001b[A\n",
            "Training:  90% 675/753 [02:25<00:16,  4.65it/s]\u001b[A\n",
            "Training:  90% 676/753 [02:25<00:16,  4.68it/s]\u001b[A\n",
            "Training:  90% 677/753 [02:25<00:16,  4.66it/s]\u001b[A\n",
            "Training:  90% 678/753 [02:25<00:16,  4.63it/s]\u001b[A\n",
            "Training:  90% 679/753 [02:25<00:15,  4.72it/s]\u001b[A\n",
            "Training:  90% 680/753 [02:26<00:15,  4.68it/s]\u001b[A\n",
            "Training:  90% 681/753 [02:26<00:15,  4.61it/s]\u001b[A\n",
            "Training:  91% 682/753 [02:26<00:15,  4.67it/s]\u001b[A\n",
            "Training:  91% 683/753 [02:26<00:15,  4.63it/s]\u001b[A\n",
            "Training:  91% 684/753 [02:26<00:14,  4.67it/s]\u001b[A\n",
            "Training:  91% 685/753 [02:27<00:14,  4.71it/s]\u001b[A\n",
            "Training:  91% 686/753 [02:27<00:14,  4.63it/s]\u001b[A\n",
            "Training:  91% 687/753 [02:27<00:13,  4.80it/s]\u001b[A\n",
            "Training:  91% 688/753 [02:27<00:13,  4.80it/s]\u001b[A\n",
            "Training:  92% 689/753 [02:27<00:13,  4.91it/s]\u001b[A\n",
            "Training:  92% 690/753 [02:28<00:12,  4.89it/s]\u001b[A\n",
            "Training:  92% 691/753 [02:28<00:12,  4.91it/s]\u001b[A\n",
            "Training:  92% 692/753 [02:28<00:12,  4.86it/s]\u001b[A\n",
            "Training:  92% 693/753 [02:28<00:12,  4.87it/s]\u001b[A\n",
            "Training:  92% 694/753 [02:29<00:12,  4.80it/s]\u001b[A\n",
            "Training:  92% 695/753 [02:29<00:12,  4.74it/s]\u001b[A\n",
            "Training:  92% 696/753 [02:29<00:11,  4.78it/s]\u001b[A\n",
            "Training:  93% 697/753 [02:29<00:11,  4.89it/s]\u001b[A\n",
            "Training:  93% 698/753 [02:29<00:11,  4.90it/s]\u001b[A\n",
            "Training:  93% 699/753 [02:30<00:11,  4.88it/s]\u001b[A\n",
            "Training:  93% 700/753 [02:30<00:11,  4.72it/s]\u001b[A\n",
            "Training:  93% 701/753 [02:30<00:10,  4.80it/s]\u001b[A\n",
            "Training:  93% 702/753 [02:30<00:10,  4.81it/s]\u001b[A\n",
            "Training:  93% 703/753 [02:30<00:10,  4.70it/s]\u001b[A\n",
            "Training:  93% 704/753 [02:31<00:10,  4.60it/s]\u001b[A\n",
            "Training:  94% 705/753 [02:31<00:10,  4.51it/s]\u001b[A\n",
            "Training:  94% 706/753 [02:31<00:10,  4.57it/s]\u001b[A\n",
            "Training:  94% 707/753 [02:31<00:10,  4.57it/s]\u001b[A\n",
            "Training:  94% 708/753 [02:32<00:09,  4.55it/s]\u001b[A\n",
            "Training:  94% 709/753 [02:32<00:09,  4.58it/s]\u001b[A\n",
            "Training:  94% 710/753 [02:32<00:09,  4.56it/s]\u001b[A\n",
            "Training:  94% 711/753 [02:32<00:08,  4.71it/s]\u001b[A\n",
            "Training:  95% 712/753 [02:32<00:08,  4.67it/s]\u001b[A\n",
            "Training:  95% 713/753 [02:33<00:08,  4.70it/s]\u001b[A\n",
            "Training:  95% 714/753 [02:33<00:08,  4.67it/s]\u001b[A\n",
            "Training:  95% 715/753 [02:33<00:08,  4.59it/s]\u001b[A\n",
            "Training:  95% 716/753 [02:33<00:07,  4.68it/s]\u001b[A\n",
            "Training:  95% 717/753 [02:33<00:07,  4.63it/s]\u001b[A\n",
            "Training:  95% 718/753 [02:34<00:07,  4.73it/s]\u001b[A\n",
            "Training:  95% 719/753 [02:34<00:07,  4.76it/s]\u001b[A\n",
            "Training:  96% 720/753 [02:34<00:06,  4.89it/s]\u001b[A\n",
            "Training:  96% 721/753 [02:34<00:06,  4.79it/s]\u001b[A\n",
            "Training:  96% 722/753 [02:34<00:06,  4.78it/s]\u001b[A\n",
            "Training:  96% 723/753 [02:35<00:06,  4.64it/s]\u001b[A\n",
            "Training:  96% 724/753 [02:35<00:06,  4.73it/s]\u001b[A\n",
            "Training:  96% 725/753 [02:35<00:05,  4.78it/s]\u001b[A\n",
            "Training:  96% 726/753 [02:35<00:05,  4.71it/s]\u001b[A\n",
            "Training:  97% 727/753 [02:36<00:05,  4.79it/s]\u001b[A\n",
            "Training:  97% 728/753 [02:36<00:05,  4.66it/s]\u001b[A\n",
            "Training:  97% 729/753 [02:36<00:05,  4.55it/s]\u001b[A\n",
            "Training:  97% 730/753 [02:36<00:04,  4.60it/s]\u001b[A\n",
            "Training:  97% 731/753 [02:36<00:04,  4.59it/s]\u001b[A\n",
            "Training:  97% 732/753 [02:37<00:04,  4.63it/s]\u001b[A\n",
            "Training:  97% 733/753 [02:37<00:04,  4.61it/s]\u001b[A\n",
            "Training:  97% 734/753 [02:37<00:04,  4.56it/s]\u001b[A\n",
            "Training:  98% 735/753 [02:37<00:03,  4.66it/s]\u001b[A\n",
            "Training:  98% 736/753 [02:38<00:03,  4.59it/s]\u001b[A\n",
            "Training:  98% 737/753 [02:38<00:03,  4.61it/s]\u001b[A\n",
            "Training:  98% 738/753 [02:38<00:03,  4.73it/s]\u001b[A\n",
            "Training:  98% 739/753 [02:38<00:03,  4.67it/s]\u001b[A\n",
            "Training:  98% 740/753 [02:38<00:02,  4.56it/s]\u001b[A\n",
            "Training:  98% 741/753 [02:39<00:02,  4.61it/s]\u001b[A\n",
            "Training:  99% 742/753 [02:39<00:02,  4.68it/s]\u001b[A\n",
            "Training:  99% 743/753 [02:39<00:02,  4.71it/s]\u001b[A\n",
            "Training:  99% 744/753 [02:39<00:01,  4.83it/s]\u001b[A\n",
            "Training:  99% 745/753 [02:39<00:01,  4.67it/s]\u001b[A\n",
            "Training:  99% 746/753 [02:40<00:01,  4.68it/s]\u001b[A\n",
            "Training:  99% 747/753 [02:40<00:01,  4.69it/s]\u001b[A\n",
            "Training:  99% 748/753 [02:40<00:01,  4.76it/s]\u001b[A\n",
            "Training:  99% 749/753 [02:40<00:00,  4.71it/s]\u001b[A\n",
            "Training: 100% 750/753 [02:40<00:00,  4.64it/s]\u001b[A\n",
            "Training: 100% 751/753 [02:41<00:00,  4.64it/s]\u001b[A\n",
            "Training: 100% 752/753 [02:41<00:00,  4.67it/s]\u001b[A\n",
            "Training: 100% 753/753 [02:41<00:00,  4.66it/s]\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.76it/s]\n",
            "2025-11-21 00:14:20,733 - INFO -   Loss: 0.4225\n",
            "2025-11-21 00:14:20,733 - INFO -   Val Macro F1: 0.7653\n",
            "2025-11-21 00:14:21,605 - INFO -   ‚úÖ Saved checkpoint (F1: 0.7653)\n",
            "2025-11-21 00:14:21,605 - INFO - Epoch 2/3\n",
            "Training: 100% 753/753 [02:41<00:00,  4.66it/s]\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.76it/s]\n",
            "2025-11-21 00:17:24,913 - INFO -   Loss: 0.3105\n",
            "2025-11-21 00:17:24,913 - INFO -   Val Macro F1: 0.7596\n",
            "2025-11-21 00:17:24,913 - INFO - Epoch 3/3\n",
            "Training: 100% 753/753 [02:41<00:00,  4.66it/s]\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.75it/s]\n",
            "2025-11-21 00:20:28,035 - INFO -   Loss: 0.2593\n",
            "2025-11-21 00:20:28,035 - INFO -   Val Macro F1: 0.7671\n",
            "2025-11-21 00:20:28,976 - INFO -   ‚úÖ Saved checkpoint (F1: 0.7671)\n",
            "2025-11-21 00:20:28,976 - INFO - ‚úÖ Stage 1 complete. Best F1: 0.7671\n",
            "2025-11-21 00:20:28,980 - INFO - ======================================================================\n",
            "2025-11-21 00:20:28,980 - INFO - STAGE 2: CONCEPT HEAD TRAINING\n",
            "2025-11-21 00:20:28,980 - INFO - ======================================================================\n",
            "2025-11-21 00:20:28,981 - INFO - Preparing data loaders with concept labels...\n",
            "2025-11-21 00:20:28,982 - INFO - Starting Stage 2 training...\n",
            "2025-11-21 00:20:28,983 - INFO - Epoch 1/2\n",
            "Training: 100% 753/753 [02:42<00:00,  4.62it/s]\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.72it/s]\n",
            "2025-11-21 00:23:33,664 - INFO -   Loss: 0.0804\n",
            "2025-11-21 00:23:33,664 - INFO -   Val Concept F1: 0.5381\n",
            "2025-11-21 00:23:34,543 - INFO -   ‚úÖ Saved checkpoint (F1: 0.5381)\n",
            "2025-11-21 00:23:34,543 - INFO - Epoch 2/2\n",
            "Training: 100% 753/753 [02:42<00:00,  4.63it/s]\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.71it/s]\n",
            "2025-11-21 00:26:39,089 - INFO -   Loss: -0.0206\n",
            "2025-11-21 00:26:39,089 - INFO -   Val Concept F1: 0.5949\n",
            "2025-11-21 00:26:40,018 - INFO -   ‚úÖ Saved checkpoint (F1: 0.5949)\n",
            "2025-11-21 00:26:40,018 - INFO - ‚úÖ Stage 2 complete. Best Concept F1: 0.5949\n",
            "2025-11-21 00:26:40,022 - INFO - ======================================================================\n",
            "2025-11-21 00:26:40,022 - INFO - STAGE 3: JOINT FINE-TUNING WITH ALIGNMENT\n",
            "2025-11-21 00:26:40,022 - INFO - ======================================================================\n",
            "2025-11-21 00:26:40,023 - INFO - Starting Stage 3 training...\n",
            "2025-11-21 00:26:40,026 - INFO - Epoch 1/3\n",
            "Training: 100% 753/753 [02:48<00:00,  4.46it/s]\n",
            "2025-11-21 00:29:28,675 - INFO -   Loss: 0.1165\n",
            "2025-11-21 00:29:28,675 - INFO -     diagnosis: 0.4193\n",
            "2025-11-21 00:29:28,675 - INFO -     concept: 0.5029\n",
            "2025-11-21 00:29:28,675 - INFO -     confidence: -0.8756\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.72it/s]\n",
            "2025-11-21 00:29:50,437 - INFO -   Val Macro F1: 0.7532\n",
            "2025-11-21 00:29:51,306 - INFO -   ‚úÖ Saved checkpoint (F1: 0.7532)\n",
            "2025-11-21 00:29:51,307 - INFO - Epoch 2/3\n",
            "Training: 100% 753/753 [02:48<00:00,  4.47it/s]\n",
            "2025-11-21 00:32:39,794 - INFO -   Loss: -0.0265\n",
            "2025-11-21 00:32:39,794 - INFO -     diagnosis: 0.1803\n",
            "2025-11-21 00:32:39,794 - INFO -     concept: 0.4353\n",
            "2025-11-21 00:32:39,794 - INFO -     confidence: -0.9018\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.71it/s]\n",
            "2025-11-21 00:33:01,622 - INFO -   Val Macro F1: 0.7557\n",
            "2025-11-21 00:33:02,588 - INFO -   ‚úÖ Saved checkpoint (F1: 0.7557)\n",
            "2025-11-21 00:33:02,588 - INFO - Epoch 3/3\n",
            "Training: 100% 753/753 [02:48<00:00,  4.46it/s]\n",
            "2025-11-21 00:35:51,401 - INFO -   Loss: -0.0652\n",
            "2025-11-21 00:35:51,402 - INFO -     diagnosis: 0.1302\n",
            "2025-11-21 00:35:51,402 - INFO -     concept: 0.3901\n",
            "2025-11-21 00:35:51,402 - INFO -     confidence: -0.9115\n",
            "Validation: 100% 81/81 [00:21<00:00,  3.71it/s]\n",
            "2025-11-21 00:36:13,264 - INFO -   Val Macro F1: 0.7669\n",
            "2025-11-21 00:36:14,185 - INFO -   ‚úÖ Saved checkpoint (F1: 0.7669)\n",
            "2025-11-21 00:36:14,186 - INFO - ‚úÖ Stage 3 complete. Best F1: 0.7669\n",
            "2025-11-21 00:36:14,481 - INFO - ================================================================================\n",
            "2025-11-21 00:36:14,481 - INFO - ‚úÖ ALL TRAINING STAGES COMPLETE!\n",
            "2025-11-21 00:36:14,481 - INFO - ================================================================================\n",
            "2025-11-21 00:36:14,481 - INFO - üìä Summary:\n",
            "2025-11-21 00:36:14,481 - INFO -    Concepts loaded: 60\n",
            "2025-11-21 00:36:14,482 - INFO -    Whitelist concepts: 60\n",
            "2025-11-21 00:36:14,482 - INFO -    Avg labels/sample: 19.3\n",
            "2025-11-21 00:36:14,482 - INFO -    Final F1: 0.7669\n",
            "2025-11-21 00:36:14,482 - INFO - üéØ Training successful!\n",
            "2025-11-21 00:36:14,482 - INFO -    Next: Run final_evaluation.py\n",
            "\n",
            "‚úÖ Training complete!\n",
            "üì¶ Model saved to: 03_Models/checkpoints/shifamind_model.pt\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ShifaMind_Capstone\n",
        "\n",
        "print(\"üéì Training ShifaMind Model...\\n\")\n",
        "print(\"This will take several hours. Progress will be shown below.\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "!python final_model_training.py\n",
        "\n",
        "print(\"\\n‚úÖ Training complete!\")\n",
        "print(\"üì¶ Model saved to: 03_Models/checkpoints/shifamind_model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF2Ps9m2uI8l"
      },
      "source": [
        "## Pipeline Step 3: Evaluate Model\n",
        "\n",
        "**Time**: ~10-15 minutes\n",
        "\n",
        "This computes comprehensive metrics and generates visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "DHsIqQi7uI8l",
        "outputId": "f40d8a65-66ef-40c9-9dd4-86f573dcbb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ShifaMind_Capstone\n",
            "üìä Evaluating Model Performance...\n",
            "\n",
            "üñ•Ô∏è  Device: cuda\n",
            "================================================================================\n",
            "SHIFAMIND 042: COMPREHENSIVE EVALUATION PIPELINE\n",
            "================================================================================\n",
            "\n",
            "üìÅ Output Directory: /content/drive/MyDrive/ShifaMind/04_Results/experiments/042_filtered_concepts\n",
            "üìÅ Checkpoint: /content/drive/MyDrive/ShifaMind/03_Models/checkpoints/shifamind_model.pt\n",
            "\n",
            "================================================================================\n",
            "STARTING COMPREHENSIVE EVALUATION\n",
            "================================================================================\n",
            "\n",
            "üìÇ Loading model and data...\n",
            "  ‚úÖ Loaded checkpoint: /content/drive/MyDrive/ShifaMind/03_Models/checkpoints/shifamind_model.pt\n",
            "  ‚úÖ Loaded 60 concept embeddings\n",
            "  Loading Bio_ClinicalBERT...\n",
            "2025-11-21 00:39:17.861801: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-21 00:39:17.877088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763685557.895097   12996 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763685557.900474   12996 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763685557.914325   12996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763685557.914352   12996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763685557.914355   12996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763685557.914358   12996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-21 00:39:17.918517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "  ‚úÖ Model initialized and loaded\n",
            "\n",
            "  Loading test data...\n",
            "  ‚ö†Ô∏è  No cached test data found. You may need to run 042.py first.\n",
            "  Attempting to load from MIMIC data...\n",
            "  ‚úÖ Loaded 1831 test samples\n",
            "  ‚úÖ Test set: 1831 samples\n",
            "\n",
            "üìä Computing diagnostic performance...\n",
            "Evaluating diagnostic performance: 100% 115/115 [00:31<00:00,  3.60it/s]\n",
            "  ‚úÖ Macro F1: 0.7989\n",
            "  ‚úÖ Macro AUROC: 0.9155\n",
            "\n",
            "üìè Computing calibration metrics...\n",
            "  ‚úÖ ECE: 0.0823\n",
            "\n",
            "üîç Computing explainability metrics...\n",
            "Evaluating explainability: 100% 115/115 [00:32<00:00,  3.56it/s]\n",
            "  ‚úÖ Citation Completeness: 100.00%\n",
            "  ‚úÖ Avg Concepts/Sample: 15.0\n",
            "  ‚úÖ Concept Alignment: 0.2031\n",
            "\n",
            "üìù Generating reasoning chains...\n",
            "Generating reasoning chains: 100% 115/115 [00:32<00:00,  3.49it/s]\n",
            "  Saved: example_001.json (J189, correct=True)\n",
            "  Saved: example_002.json (I5023, correct=False)\n",
            "  Saved: example_003.json (I5023, correct=True)\n",
            "  Saved: example_004.json (I5023, correct=False)\n",
            "  Saved: example_005.json (A419, correct=True)\n",
            "  Saved: example_006.json (A419, correct=False)\n",
            "  Saved: example_007.json (K8000, correct=True)\n",
            "  Saved: example_008.json (K8000, correct=False)\n",
            "  Saved: example_009.json (A419, correct=True)\n",
            "  Saved: example_010.json (A419, correct=True)\n",
            "  ‚úÖ Generated 10 reasoning chain examples\n",
            "\n",
            "üìà Creating visualizations...\n",
            "  Saved: confusion_matrices.png\n",
            "  Saved: calibration_curve.png\n",
            "  Saved: per_class_performance.png\n",
            "  Saved: metrics_summary.png\n",
            "  ‚úÖ Created 4 visualization figures\n",
            "\n",
            "üíæ Saving results...\n",
            "  ‚úÖ Saved: evaluation_metrics.json\n",
            "  ‚úÖ Saved: test_predictions.csv\n",
            "\n",
            "================================================================================\n",
            "EVALUATION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "üìä RESULTS SUMMARY:\n",
            "\n",
            "  Diagnostic Performance:\n",
            "    Macro F1: 0.7989\n",
            "    Micro F1: 0.7749\n",
            "    Macro AUROC: 0.9155\n",
            "\n",
            "  Calibration:\n",
            "    ECE: 0.0823\n",
            "\n",
            "  Explainability:\n",
            "    Citation Completeness: 100.00%\n",
            "    Avg Concepts/Sample: 15.0\n",
            "    Concept Alignment: 0.2031\n",
            "\n",
            "  Per-Class F1 Scores:\n",
            "    J189: 0.7720\n",
            "    I5023: 0.8430\n",
            "    A419: 0.7274\n",
            "    K8000: 0.8533\n",
            "\n",
            "üìÅ Output Files:\n",
            "  Metrics: /content/drive/MyDrive/ShifaMind/04_Results/experiments/042_filtered_concepts/evaluation_metrics.json\n",
            "  Predictions: /content/drive/MyDrive/ShifaMind/04_Results/experiments/042_filtered_concepts/test_predictions.csv\n",
            "  Reasoning Chains: /content/drive/MyDrive/ShifaMind/04_Results/experiments/042_filtered_concepts/reasoning_chains/ (10 files)\n",
            "  Figures: /content/drive/MyDrive/ShifaMind/04_Results/experiments/042_filtered_concepts/figures/ (4 files)\n",
            "\n",
            "‚úÖ All evaluation tasks completed successfully!\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Evaluation complete!\n",
            "üìÅ Results saved to: 04_Results/experiments/\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ShifaMind_Capstone\n",
        "\n",
        "print(\"üìä Evaluating Model Performance...\\n\")\n",
        "!python final_evaluation.py\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation complete!\")\n",
        "print(\"üìÅ Results saved to: 04_Results/experiments/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apv2y48ouI8l"
      },
      "source": [
        "## Pipeline Step 4: Launch Interactive Demo\n",
        "\n",
        "**Time**: Instant\n",
        "\n",
        "This launches a Gradio web interface where you can test predictions on clinical notes.\n",
        "\n",
        "**Note**: The demo will create a public URL you can share (valid for 72 hours)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# The file the script expects\n",
        "expected_path = \"/content/drive/MyDrive/ShifaMind/03_Models/clinical_knowledge_base.json\"\n",
        "\n",
        "# Your actual file (adjust the number if different)\n",
        "actual_path = \"/content/drive/MyDrive/ShifaMind/03_Models/clinical_knowledge_base_043.json\"\n",
        "\n",
        "# Copy with the correct name\n",
        "if os.path.exists(actual_path):\n",
        "    shutil.copy2(actual_path, expected_path)\n",
        "    print(f\"‚úÖ Copied KB to: {expected_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Source file not found: {actual_path}\")\n",
        "    print(\"\\nTry listing files to find the correct name:\")\n",
        "    !ls -lh /content/drive/MyDrive/ShifaMind/03_Models/*.json"
      ],
      "metadata": {
        "id": "M06lhtFu-op7",
        "outputId": "24dcb014-7bd3-489c-d336-ff75a0fba9c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Copied KB to: /content/drive/MyDrive/ShifaMind/03_Models/clinical_knowledge_base.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "SGr5TaahuI8l",
        "outputId": "3b7a8c48-1cb3-458d-b8d3-9f6c9b02b77e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Using BASE_PATH: /content/drive/MyDrive/ShifaMind\n",
            "üåê Launching demo...\n",
            "\n",
            "üìÇ Using BASE_PATH: /content/drive/MyDrive/ShifaMind\n",
            "üì¶ Looking for model at: /content/drive/MyDrive/ShifaMind/03_Models/checkpoints/shifamind_model.pt\n",
            "üìö Looking for KB at: /content/drive/MyDrive/ShifaMind/03_Models/clinical_knowledge_base.json\n",
            "================================================================================\n",
            "üè• SHIFAMIND: LIVE DEMO (FILTERED)\n",
            "================================================================================\n",
            "\n",
            "üìÇ Loading checkpoint...\n",
            "  ‚úÖ Loaded 60 concepts\n",
            "\n",
            "üì¶ Loading Bio_ClinicalBERT...\n",
            "2025-11-21 01:15:17.001287: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-21 01:15:17.017312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763687717.035611   22272 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763687717.040952   22272 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763687717.054917   22272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763687717.054941   22272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763687717.054944   22272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763687717.054947   22272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-21 01:15:17.059076: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "  ‚úÖ Model ready\n",
            "\n",
            "üìö Loading knowledge base...\n",
            "  ‚úÖ Knowledge base loaded\n",
            "\n",
            "‚úÖ All components ready! (WITH ANIMAL FILTERING)\n",
            "================================================================================\n",
            "\n",
            "\n",
            "üöÄ LAUNCHING FILTERED DEMO\n",
            "================================================================================\n",
            "\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://c3d60823cc9f27b7ea.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "  üö´ Filtered 1 animal/veterinary concepts\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2958, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ShifaMind_Capstone/final_demo.py\", line 672, in <module>\n",
            "    demo.launch(share=True, server_port=None, show_error=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2865, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2962, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1153, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "                                       ^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c3d60823cc9f27b7ea.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# Set environment variable\n",
        "os.environ['SHIFAMIND_BASE_PATH'] = '/content/drive/MyDrive/ShifaMind'\n",
        "\n",
        "print(f\"üìÇ Using BASE_PATH: {os.environ['SHIFAMIND_BASE_PATH']}\")\n",
        "print(\"üåê Launching demo...\\n\")\n",
        "\n",
        "!python final_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XiKKPz8uI8m"
      },
      "source": [
        "---\n",
        "\n",
        "# üéâ Setup Complete!\n",
        "\n",
        "You've successfully:\n",
        "- ‚úÖ Set up ShifaMind on Google Colab\n",
        "- ‚úÖ Generated the clinical knowledge base\n",
        "- ‚úÖ Trained the model (if you ran the training step)\n",
        "- ‚úÖ Evaluated performance\n",
        "- ‚úÖ Tested inference\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Explore Results**: Check the `04_Results/experiments/` folder for metrics and visualizations\n",
        "2. **Use the Demo**: Run the demo cell above to get an interactive web interface\n",
        "3. **Integrate into Your App**: Import `ShifaMindPredictor` and use it in your own code\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "- **Path Errors**: Re-run Step 3 and verify all paths exist\n",
        "- **Out of Memory**: Use a smaller batch size or upgrade to Colab Pro for more RAM\n",
        "- **GPU Not Available**: Go to Runtime > Change runtime type > Select GPU\n",
        "- **Session Timeout**: Use Colab Pro or keep browser tab active during training\n",
        "\n",
        "## Support\n",
        "\n",
        "For issues or questions:\n",
        "- Check the README.md in the repository\n",
        "- Review the documentation in the `docs/` folder\n",
        "- Contact: Mohammed Sameer Syed\n",
        "\n",
        "---\n",
        "\n",
        "**Built with precision. Designed for transparency. Created for better healthcare.**\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ShifaMind_Colab_Setup.ipynb",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}